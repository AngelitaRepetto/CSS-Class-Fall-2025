[
  {
    "objectID": "assignments/Lab One.html",
    "href": "assignments/Lab One.html",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "R is both a programming language and an environment for statistical computing. Let‚Äôs start with the basics.\n\n\n\n# R as a calculator\n2 + 3\n10 - 4\n6 * 7\n20 / 4\n2^3  # exponentiation\nsqrt(16)  # square root\nlog(10)   # natural logarithm\nexp(1)    # e^1\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n[1] 6\n\n\n[1] 42\n\n\n[1] 5\n\n\n[1] 8\n\n\n[1] 4\n\n\n[1] 2.302585\n\n\n[1] 2.718282\n\n\n\n\n\n\n\n\n\n# Order of operations\n2 + 3 * 4\n(2 + 3) * 4\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 14\n\n\n[1] 20\n\n\n\n\n\n\n\n\n\n# Mathematical functions\nabs(-5)\nround(3.14159, 2)\nceiling(3.2)\nfloor(3.8)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n[1] 3.14\n\n\n[1] 4\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\nUnderstanding how to store and manipulate data is crucial in R.\n\n\n\n# Creating variables\nx &lt;- 10\ny &lt;- 5\nname &lt;- \"Alice\"\nuniversity &lt;- \"State University\"\n\n# Using variables\nresult &lt;- x + y\nmessage &lt;- paste(\"Hello\", name, \"from\", university)\nprint(result)\nprint(message)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 15\n\n\n[1] \"Hello Alice from State University\"\n\n\n\n\n\n\n\n\n\n# Multiple assignment\na &lt;- b &lt;- c &lt;- 100\nprint(c(a, b, c))\n\n# Variable naming conventions\nstudent_name &lt;- \"John Doe\"  # snake_case (recommended)\nstudentName &lt;- \"Jane Smith\"  # camelCase\nstudent.name &lt;- \"Bob Johnson\"  # dot notation (less common)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 100 100 100\n\n\n\n\n\n\n\n\n\n# Check what's in your environment\nls()  # List all variables\nrm(x, y)  # Remove specific variables\nls()  # Check again\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n [1] \"a\"               \"b\"               \"c\"               \"has_annotations\"\n [5] \"message\"         \"name\"            \"result\"          \"student_name\"   \n [9] \"student.name\"    \"studentName\"     \"university\"      \"x\"              \n[13] \"y\"              \n\n\n [1] \"a\"               \"b\"               \"c\"               \"has_annotations\"\n [5] \"message\"         \"name\"            \"result\"          \"student_name\"   \n [9] \"student.name\"    \"studentName\"     \"university\"     \n\n\n\n\n\n\n\n\n\nR has several data types. Understanding them is fundamental to effective programming.\n\n\n\n# Basic data types\nage &lt;- 25L          # Integer (note the L)\nheight &lt;- 5.8       # Numeric (double)\nstudent_name &lt;- \"John Doe\"  # Character\nis_enrolled &lt;- TRUE # Logical\ngrade &lt;- 'A'        # Character (single quotes also work)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Check data types\ntypeof(age)\ntypeof(height)\ntypeof(student_name)\ntypeof(is_enrolled)\n\n# Also use class() function\nclass(age)\nclass(height)\nclass(student_name)\nclass(is_enrolled)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"integer\"\n\n\n[1] \"double\"\n\n\n[1] \"character\"\n\n\n[1] \"logical\"\n\n\n[1] \"integer\"\n\n\n[1] \"numeric\"\n\n\n[1] \"character\"\n\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n\n# Type conversion\nas.numeric(\"123\")\nas.character(456)\nas.logical(1)  # 1 becomes TRUE, 0 becomes FALSE\nas.integer(3.14)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 123\n\n\n[1] \"456\"\n\n\n[1] TRUE\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\n# Special values\nmissing_value &lt;- NA  # Not Available\ninfinite_value &lt;- Inf\nnot_a_number &lt;- NaN\n\n# Check for special values\nis.na(missing_value)\nis.infinite(infinite_value)\nis.nan(not_a_number)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] TRUE\n\n\n[1] TRUE\n\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\nVectors are the most basic data structure in R. Everything in R is built from vectors.\n\n\n\n# Creating vectors\ngrades &lt;- c(85, 92, 78, 96, 88)\nstudent_names &lt;- c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\")\npassed &lt;- c(TRUE, TRUE, FALSE, TRUE, TRUE)\n\n# Vector properties\nlength(grades)\nnames(grades) &lt;- student_names  # Adding names to vector elements\nprint(grades)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n  Alice     Bob Charlie   Diana     Eve \n     85      92      78      96      88 \n\n\n\n\n\n\n\n\n\n# Accessing vector elements (1-indexed!)\ngrades[1]              # First element\ngrades[2:4]            # Elements 2 through 4\ngrades[c(1, 3, 5)]     # Specific elements\ngrades[\"Alice\"]        # Using names\ngrades[grades &gt; 90]    # Conditional indexing\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nAlice \n   85 \n\n\n    Bob Charlie   Diana \n     92      78      96 \n\n\n  Alice Charlie     Eve \n     85      78      88 \n\n\nAlice \n   85 \n\n\n  Bob Diana \n   92    96 \n\n\n\n\n\n\n\n\n\n# Vector operations (vectorized!)\ngrades + 5             # Add 5 to all grades\ngrades * 1.1           # Multiply all by 1.1\ngrades &gt; 85            # Logical comparison\nwhich(grades &gt; 85)     # Which positions are TRUE\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n  Alice     Bob Charlie   Diana     Eve \n     90      97      83     101      93 \n\n\n  Alice     Bob Charlie   Diana     Eve \n   93.5   101.2    85.8   105.6    96.8 \n\n\n  Alice     Bob Charlie   Diana     Eve \n  FALSE    TRUE   FALSE    TRUE    TRUE \n\n\n  Bob Diana   Eve \n    2     4     5 \n\n\n\n\n\n\n\n\n\n# Useful vector functions\nsum(grades)\nmean(grades)\nmedian(grades)\nmax(grades)\nmin(grades)\nrange(grades)\nsort(grades)\nsort(grades, decreasing = TRUE)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 439\n\n\n[1] 87.8\n\n\n[1] 88\n\n\n[1] 96\n\n\n[1] 78\n\n\n[1] 78 96\n\n\nCharlie   Alice     Eve     Bob   Diana \n     78      85      88      92      96 \n\n\n  Diana     Bob     Eve   Alice Charlie \n     96      92      88      85      78 \n\n\n\n\n\n\n\n\n\n# Creating sequences\nseq(1, 10, by = 2)     # 1, 3, 5, 7, 9\nseq(0, 1, length.out = 5)  # 5 equally spaced numbers\n1:10                   # Shorthand for seq(1, 10, by = 1)\nrep(c(\"A\", \"B\"), times = 3)  # Repeat vector\nrep(c(\"A\", \"B\"), each = 3)   # Repeat each element\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 1 3 5 7 9\n\n\n[1] 0.00 0.25 0.50 0.75 1.00\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n[1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\"\n\n\n[1] \"A\" \"A\" \"A\" \"B\" \"B\" \"B\"\n\n\n\n\n\n\n\n\n\nData frames are the primary way to work with structured data in R.\n\n\n\n# Creating a data frame\nstudents &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"),\n  age = c(20, 21, 19, 22, 20),\n  grade = c(85, 92, 78, 96, 88),\n  major = c(\"Biology\", \"Physics\", \"Chemistry\", \"Biology\", \"Math\"),\n  gpa = c(3.4, 3.7, 3.1, 3.8, 3.5),\n  stringsAsFactors = FALSE  # Keep character columns as characters\n)\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n4   Diana  22    96   Biology 3.8\n5     Eve  20    88      Math 3.5\n\n\n\n\n\n\n\n\n\n# Viewing the data frame\nhead(students, 3)      # First 3 rows\ntail(students, 2)      # Last 2 rows\nstr(students)          # Structure of the data frame\nsummary(students)      # Summary statistics\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n\n\n   name age grade   major gpa\n4 Diana  22    96 Biology 3.8\n5   Eve  20    88    Math 3.5\n\n\n'data.frame':   5 obs. of  5 variables:\n $ name : chr  \"Alice\" \"Bob\" \"Charlie\" \"Diana\" ...\n $ age  : num  20 21 19 22 20\n $ grade: num  85 92 78 96 88\n $ major: chr  \"Biology\" \"Physics\" \"Chemistry\" \"Biology\" ...\n $ gpa  : num  3.4 3.7 3.1 3.8 3.5\n\n\n     name                age           grade         major          \n Length:5           Min.   :19.0   Min.   :78.0   Length:5          \n Class :character   1st Qu.:20.0   1st Qu.:85.0   Class :character  \n Mode  :character   Median :20.0   Median :88.0   Mode  :character  \n                    Mean   :20.4   Mean   :87.8                     \n                    3rd Qu.:21.0   3rd Qu.:92.0                     \n                    Max.   :22.0   Max.   :96.0                     \n      gpa     \n Min.   :3.1  \n 1st Qu.:3.4  \n Median :3.5  \n Mean   :3.5  \n 3rd Qu.:3.7  \n Max.   :3.8  \n\n\n\n\n\n\n\n\n\n# Data frame dimensions and properties\ndim(students)          # Dimensions (rows, columns)\nnrow(students)         # Number of rows\nncol(students)         # Number of columns\nnames(students)        # Column names\nrownames(students)     # Row names\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5 5\n\n\n[1] 5\n\n\n[1] 5\n\n\n[1] \"name\"  \"age\"   \"grade\" \"major\" \"gpa\"  \n\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\n\n\n\n\n\n\n\n# Accessing data frame elements\nstudents$name              # Using $\nstudents[, \"grade\"]        # Using column name\nstudents[, 3]             # Using column index\nstudents[\"grade\"]         # Returns data frame\nstudents[[\"grade\"]]       # Returns vector\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"    \n\n\n[1] 85 92 78 96 88\n\n\n[1] 85 92 78 96 88\n\n\n  grade\n1    85\n2    92\n3    78\n4    96\n5    88\n\n\n[1] 85 92 78 96 88\n\n\n\n\n\n\n\n\n\n# Multiple columns\nstudents[, c(\"name\", \"grade\")]\nstudents[, c(1, 3)]\n\n# Accessing rows\nstudents[1, ]             # First row\nstudents[2:3, ]           # Rows 2 and 3\nstudents[c(1, 3, 5), ]    # Specific rows\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name grade\n1   Alice    85\n2     Bob    92\n3 Charlie    78\n4   Diana    96\n5     Eve    88\n\n\n     name grade\n1   Alice    85\n2     Bob    92\n3 Charlie    78\n4   Diana    96\n5     Eve    88\n\n\n   name age grade   major gpa\n1 Alice  20    85 Biology 3.4\n\n\n     name age grade     major gpa\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n3 Charlie  19    78 Chemistry 3.1\n5     Eve  20    88      Math 3.5\n\n\n\n\n\n\n\n\n\n# Accessing specific cells\nstudents[1, \"name\"]       # First row, name column\nstudents[2, 3]            # Second row, third column\n\n# Conditional filtering\nhigh_performers &lt;- students[students$grade &gt; 90, ]\nbiology_students &lt;- students[students$major == \"Biology\", ]\nyoung_high_performers &lt;- students[students$age &lt; 21 & students$grade &gt; 85, ]\n\nprint(\"High performers:\")\nprint(high_performers)\nprint(\"Biology students:\")\nprint(biology_students)\nprint(\"Young high performers:\")\nprint(young_high_performers)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Alice\"\n\n\n[1] 92\n\n\n[1] \"High performers:\"\n\n\n   name age grade   major gpa\n2   Bob  21    92 Physics 3.7\n4 Diana  22    96 Biology 3.8\n\n\n[1] \"Biology students:\"\n\n\n   name age grade   major gpa\n1 Alice  20    85 Biology 3.4\n4 Diana  22    96 Biology 3.8\n\n\n[1] \"Young high performers:\"\n\n\n  name age grade major gpa\n5  Eve  20    88  Math 3.5\n\n\n\n\n\n\n\n\n\n# Adding and modifying columns\nstudents$letter_grade &lt;- ifelse(students$grade &gt;= 90, \"A\",\n                               ifelse(students$grade &gt;= 80, \"B\",\n                               ifelse(students$grade &gt;= 70, \"C\", \"D\")))\n\nstudents$status &lt;- ifelse(students$grade &gt;= 80, \"Pass\", \"Fail\")\nstudents$age_group &lt;- cut(students$age, \n                         breaks = c(0, 20, 22, Inf),\n                         labels = c(\"Young\", \"Medium\", \"Older\"))\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa letter_grade status age_group\n1   Alice  20    85   Biology 3.4            B   Pass     Young\n2     Bob  21    92   Physics 3.7            A   Pass    Medium\n3 Charlie  19    78 Chemistry 3.1            C   Fail     Young\n4   Diana  22    96   Biology 3.8            A   Pass    Medium\n5     Eve  20    88      Math 3.5            B   Pass     Young\n\n\n\n\n\n\n\n\n\n# Removing columns\nstudents$age_group &lt;- NULL  # Remove column\n\n# Reordering columns\nstudents &lt;- students[, c(\"name\", \"age\", \"major\", \"grade\", \"gpa\", \"letter_grade\", \"status\")]\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age     major grade gpa letter_grade status\n1   Alice  20   Biology    85 3.4            B   Pass\n2     Bob  21   Physics    92 3.7            A   Pass\n3 Charlie  19 Chemistry    78 3.1            C   Fail\n4   Diana  22   Biology    96 3.8            A   Pass\n5     Eve  20      Math    88 3.5            B   Pass"
  },
  {
    "objectID": "assignments/Lab One.html#part-1-r-fundamentals-and-data-structures-60-minutes",
    "href": "assignments/Lab One.html#part-1-r-fundamentals-and-data-structures-60-minutes",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "R is both a programming language and an environment for statistical computing. Let‚Äôs start with the basics.\n\n\n\n# R as a calculator\n2 + 3\n10 - 4\n6 * 7\n20 / 4\n2^3  # exponentiation\nsqrt(16)  # square root\nlog(10)   # natural logarithm\nexp(1)    # e^1\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n[1] 6\n\n\n[1] 42\n\n\n[1] 5\n\n\n[1] 8\n\n\n[1] 4\n\n\n[1] 2.302585\n\n\n[1] 2.718282\n\n\n\n\n\n\n\n\n\n# Order of operations\n2 + 3 * 4\n(2 + 3) * 4\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 14\n\n\n[1] 20\n\n\n\n\n\n\n\n\n\n# Mathematical functions\nabs(-5)\nround(3.14159, 2)\nceiling(3.2)\nfloor(3.8)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n[1] 3.14\n\n\n[1] 4\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\nUnderstanding how to store and manipulate data is crucial in R.\n\n\n\n# Creating variables\nx &lt;- 10\ny &lt;- 5\nname &lt;- \"Alice\"\nuniversity &lt;- \"State University\"\n\n# Using variables\nresult &lt;- x + y\nmessage &lt;- paste(\"Hello\", name, \"from\", university)\nprint(result)\nprint(message)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 15\n\n\n[1] \"Hello Alice from State University\"\n\n\n\n\n\n\n\n\n\n# Multiple assignment\na &lt;- b &lt;- c &lt;- 100\nprint(c(a, b, c))\n\n# Variable naming conventions\nstudent_name &lt;- \"John Doe\"  # snake_case (recommended)\nstudentName &lt;- \"Jane Smith\"  # camelCase\nstudent.name &lt;- \"Bob Johnson\"  # dot notation (less common)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 100 100 100\n\n\n\n\n\n\n\n\n\n# Check what's in your environment\nls()  # List all variables\nrm(x, y)  # Remove specific variables\nls()  # Check again\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n [1] \"a\"               \"b\"               \"c\"               \"has_annotations\"\n [5] \"message\"         \"name\"            \"result\"          \"student_name\"   \n [9] \"student.name\"    \"studentName\"     \"university\"      \"x\"              \n[13] \"y\"              \n\n\n [1] \"a\"               \"b\"               \"c\"               \"has_annotations\"\n [5] \"message\"         \"name\"            \"result\"          \"student_name\"   \n [9] \"student.name\"    \"studentName\"     \"university\"     \n\n\n\n\n\n\n\n\n\nR has several data types. Understanding them is fundamental to effective programming.\n\n\n\n# Basic data types\nage &lt;- 25L          # Integer (note the L)\nheight &lt;- 5.8       # Numeric (double)\nstudent_name &lt;- \"John Doe\"  # Character\nis_enrolled &lt;- TRUE # Logical\ngrade &lt;- 'A'        # Character (single quotes also work)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Check data types\ntypeof(age)\ntypeof(height)\ntypeof(student_name)\ntypeof(is_enrolled)\n\n# Also use class() function\nclass(age)\nclass(height)\nclass(student_name)\nclass(is_enrolled)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"integer\"\n\n\n[1] \"double\"\n\n\n[1] \"character\"\n\n\n[1] \"logical\"\n\n\n[1] \"integer\"\n\n\n[1] \"numeric\"\n\n\n[1] \"character\"\n\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n\n# Type conversion\nas.numeric(\"123\")\nas.character(456)\nas.logical(1)  # 1 becomes TRUE, 0 becomes FALSE\nas.integer(3.14)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 123\n\n\n[1] \"456\"\n\n\n[1] TRUE\n\n\n[1] 3\n\n\n\n\n\n\n\n\n\n# Special values\nmissing_value &lt;- NA  # Not Available\ninfinite_value &lt;- Inf\nnot_a_number &lt;- NaN\n\n# Check for special values\nis.na(missing_value)\nis.infinite(infinite_value)\nis.nan(not_a_number)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] TRUE\n\n\n[1] TRUE\n\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\nVectors are the most basic data structure in R. Everything in R is built from vectors.\n\n\n\n# Creating vectors\ngrades &lt;- c(85, 92, 78, 96, 88)\nstudent_names &lt;- c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\")\npassed &lt;- c(TRUE, TRUE, FALSE, TRUE, TRUE)\n\n# Vector properties\nlength(grades)\nnames(grades) &lt;- student_names  # Adding names to vector elements\nprint(grades)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5\n\n\n  Alice     Bob Charlie   Diana     Eve \n     85      92      78      96      88 \n\n\n\n\n\n\n\n\n\n# Accessing vector elements (1-indexed!)\ngrades[1]              # First element\ngrades[2:4]            # Elements 2 through 4\ngrades[c(1, 3, 5)]     # Specific elements\ngrades[\"Alice\"]        # Using names\ngrades[grades &gt; 90]    # Conditional indexing\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nAlice \n   85 \n\n\n    Bob Charlie   Diana \n     92      78      96 \n\n\n  Alice Charlie     Eve \n     85      78      88 \n\n\nAlice \n   85 \n\n\n  Bob Diana \n   92    96 \n\n\n\n\n\n\n\n\n\n# Vector operations (vectorized!)\ngrades + 5             # Add 5 to all grades\ngrades * 1.1           # Multiply all by 1.1\ngrades &gt; 85            # Logical comparison\nwhich(grades &gt; 85)     # Which positions are TRUE\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n  Alice     Bob Charlie   Diana     Eve \n     90      97      83     101      93 \n\n\n  Alice     Bob Charlie   Diana     Eve \n   93.5   101.2    85.8   105.6    96.8 \n\n\n  Alice     Bob Charlie   Diana     Eve \n  FALSE    TRUE   FALSE    TRUE    TRUE \n\n\n  Bob Diana   Eve \n    2     4     5 \n\n\n\n\n\n\n\n\n\n# Useful vector functions\nsum(grades)\nmean(grades)\nmedian(grades)\nmax(grades)\nmin(grades)\nrange(grades)\nsort(grades)\nsort(grades, decreasing = TRUE)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 439\n\n\n[1] 87.8\n\n\n[1] 88\n\n\n[1] 96\n\n\n[1] 78\n\n\n[1] 78 96\n\n\nCharlie   Alice     Eve     Bob   Diana \n     78      85      88      92      96 \n\n\n  Diana     Bob     Eve   Alice Charlie \n     96      92      88      85      78 \n\n\n\n\n\n\n\n\n\n# Creating sequences\nseq(1, 10, by = 2)     # 1, 3, 5, 7, 9\nseq(0, 1, length.out = 5)  # 5 equally spaced numbers\n1:10                   # Shorthand for seq(1, 10, by = 1)\nrep(c(\"A\", \"B\"), times = 3)  # Repeat vector\nrep(c(\"A\", \"B\"), each = 3)   # Repeat each element\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 1 3 5 7 9\n\n\n[1] 0.00 0.25 0.50 0.75 1.00\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n[1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\"\n\n\n[1] \"A\" \"A\" \"A\" \"B\" \"B\" \"B\"\n\n\n\n\n\n\n\n\n\nData frames are the primary way to work with structured data in R.\n\n\n\n# Creating a data frame\nstudents &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"),\n  age = c(20, 21, 19, 22, 20),\n  grade = c(85, 92, 78, 96, 88),\n  major = c(\"Biology\", \"Physics\", \"Chemistry\", \"Biology\", \"Math\"),\n  gpa = c(3.4, 3.7, 3.1, 3.8, 3.5),\n  stringsAsFactors = FALSE  # Keep character columns as characters\n)\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n4   Diana  22    96   Biology 3.8\n5     Eve  20    88      Math 3.5\n\n\n\n\n\n\n\n\n\n# Viewing the data frame\nhead(students, 3)      # First 3 rows\ntail(students, 2)      # Last 2 rows\nstr(students)          # Structure of the data frame\nsummary(students)      # Summary statistics\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n\n\n   name age grade   major gpa\n4 Diana  22    96 Biology 3.8\n5   Eve  20    88    Math 3.5\n\n\n'data.frame':   5 obs. of  5 variables:\n $ name : chr  \"Alice\" \"Bob\" \"Charlie\" \"Diana\" ...\n $ age  : num  20 21 19 22 20\n $ grade: num  85 92 78 96 88\n $ major: chr  \"Biology\" \"Physics\" \"Chemistry\" \"Biology\" ...\n $ gpa  : num  3.4 3.7 3.1 3.8 3.5\n\n\n     name                age           grade         major          \n Length:5           Min.   :19.0   Min.   :78.0   Length:5          \n Class :character   1st Qu.:20.0   1st Qu.:85.0   Class :character  \n Mode  :character   Median :20.0   Median :88.0   Mode  :character  \n                    Mean   :20.4   Mean   :87.8                     \n                    3rd Qu.:21.0   3rd Qu.:92.0                     \n                    Max.   :22.0   Max.   :96.0                     \n      gpa     \n Min.   :3.1  \n 1st Qu.:3.4  \n Median :3.5  \n Mean   :3.5  \n 3rd Qu.:3.7  \n Max.   :3.8  \n\n\n\n\n\n\n\n\n\n# Data frame dimensions and properties\ndim(students)          # Dimensions (rows, columns)\nnrow(students)         # Number of rows\nncol(students)         # Number of columns\nnames(students)        # Column names\nrownames(students)     # Row names\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5 5\n\n\n[1] 5\n\n\n[1] 5\n\n\n[1] \"name\"  \"age\"   \"grade\" \"major\" \"gpa\"  \n\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\n\n\n\n\n\n\n\n# Accessing data frame elements\nstudents$name              # Using $\nstudents[, \"grade\"]        # Using column name\nstudents[, 3]             # Using column index\nstudents[\"grade\"]         # Returns data frame\nstudents[[\"grade\"]]       # Returns vector\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"Diana\"   \"Eve\"    \n\n\n[1] 85 92 78 96 88\n\n\n[1] 85 92 78 96 88\n\n\n  grade\n1    85\n2    92\n3    78\n4    96\n5    88\n\n\n[1] 85 92 78 96 88\n\n\n\n\n\n\n\n\n\n# Multiple columns\nstudents[, c(\"name\", \"grade\")]\nstudents[, c(1, 3)]\n\n# Accessing rows\nstudents[1, ]             # First row\nstudents[2:3, ]           # Rows 2 and 3\nstudents[c(1, 3, 5), ]    # Specific rows\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name grade\n1   Alice    85\n2     Bob    92\n3 Charlie    78\n4   Diana    96\n5     Eve    88\n\n\n     name grade\n1   Alice    85\n2     Bob    92\n3 Charlie    78\n4   Diana    96\n5     Eve    88\n\n\n   name age grade   major gpa\n1 Alice  20    85 Biology 3.4\n\n\n     name age grade     major gpa\n2     Bob  21    92   Physics 3.7\n3 Charlie  19    78 Chemistry 3.1\n\n\n     name age grade     major gpa\n1   Alice  20    85   Biology 3.4\n3 Charlie  19    78 Chemistry 3.1\n5     Eve  20    88      Math 3.5\n\n\n\n\n\n\n\n\n\n# Accessing specific cells\nstudents[1, \"name\"]       # First row, name column\nstudents[2, 3]            # Second row, third column\n\n# Conditional filtering\nhigh_performers &lt;- students[students$grade &gt; 90, ]\nbiology_students &lt;- students[students$major == \"Biology\", ]\nyoung_high_performers &lt;- students[students$age &lt; 21 & students$grade &gt; 85, ]\n\nprint(\"High performers:\")\nprint(high_performers)\nprint(\"Biology students:\")\nprint(biology_students)\nprint(\"Young high performers:\")\nprint(young_high_performers)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Alice\"\n\n\n[1] 92\n\n\n[1] \"High performers:\"\n\n\n   name age grade   major gpa\n2   Bob  21    92 Physics 3.7\n4 Diana  22    96 Biology 3.8\n\n\n[1] \"Biology students:\"\n\n\n   name age grade   major gpa\n1 Alice  20    85 Biology 3.4\n4 Diana  22    96 Biology 3.8\n\n\n[1] \"Young high performers:\"\n\n\n  name age grade major gpa\n5  Eve  20    88  Math 3.5\n\n\n\n\n\n\n\n\n\n# Adding and modifying columns\nstudents$letter_grade &lt;- ifelse(students$grade &gt;= 90, \"A\",\n                               ifelse(students$grade &gt;= 80, \"B\",\n                               ifelse(students$grade &gt;= 70, \"C\", \"D\")))\n\nstudents$status &lt;- ifelse(students$grade &gt;= 80, \"Pass\", \"Fail\")\nstudents$age_group &lt;- cut(students$age, \n                         breaks = c(0, 20, 22, Inf),\n                         labels = c(\"Young\", \"Medium\", \"Older\"))\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age grade     major gpa letter_grade status age_group\n1   Alice  20    85   Biology 3.4            B   Pass     Young\n2     Bob  21    92   Physics 3.7            A   Pass    Medium\n3 Charlie  19    78 Chemistry 3.1            C   Fail     Young\n4   Diana  22    96   Biology 3.8            A   Pass    Medium\n5     Eve  20    88      Math 3.5            B   Pass     Young\n\n\n\n\n\n\n\n\n\n# Removing columns\nstudents$age_group &lt;- NULL  # Remove column\n\n# Reordering columns\nstudents &lt;- students[, c(\"name\", \"age\", \"major\", \"grade\", \"gpa\", \"letter_grade\", \"status\")]\n\nprint(students)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     name age     major grade gpa letter_grade status\n1   Alice  20   Biology    85 3.4            B   Pass\n2     Bob  21   Physics    92 3.7            A   Pass\n3 Charlie  19 Chemistry    78 3.1            C   Fail\n4   Diana  22   Biology    96 3.8            A   Pass\n5     Eve  20      Math    88 3.5            B   Pass"
  },
  {
    "objectID": "assignments/Lab One.html#practice-exercises",
    "href": "assignments/Lab One.html#practice-exercises",
    "title": "Lab One: Part Two",
    "section": "Practice Exercises",
    "text": "Practice Exercises\nüîç Exercise 1a: Create a vector of temperatures in Fahrenheit: 32, 68, 86, 104, 122. Convert them to Celsius using the formula: C = (F - 32) * 5/9. Find the average temperature in Celsius.\n\n\n\n\n\n\nClick to see Exercise 1a Answer\n\n\n\n\n\n\n# Create vector of Fahrenheit temperatures\nfahrenheit &lt;- c(32, 68, 86, 104, 122)\n\n# Convert to Celsius\ncelsius &lt;- (fahrenheit - 32) * 5/9\n\n# Display the conversion\nprint(\"Fahrenheit temperatures:\")\n\n[1] \"Fahrenheit temperatures:\"\n\nprint(fahrenheit)\n\n[1]  32  68  86 104 122\n\nprint(\"Celsius temperatures:\")\n\n[1] \"Celsius temperatures:\"\n\nprint(celsius)\n\n[1]  0 20 30 40 50\n\n# Find average temperature in Celsius\navg_celsius &lt;- mean(celsius)\nprint(paste(\"Average temperature in Celsius:\", round(avg_celsius, 2)))\n\n[1] \"Average temperature in Celsius: 28\"\n\n\nThe temperatures in Celsius are: 0¬∞C, 20¬∞C, 30¬∞C, 40¬∞C, 50¬∞C The average temperature in Celsius is 28¬∞C.\n\n\n\nüîç Exercise 1b: Create a data frame with information about 5 books including title, author, year published, and number of pages. Filter for books published after 2000 and calculate the average number of pages.\n\n\n\n\n\n\nClick to see Exercise 1b Answer\n\n\n\n\n\n\n# Create data frame with book information\nbooks &lt;- data.frame(\n  title = c(\"The Hunger Games\", \"1984\", \"To Kill a Mockingbird\", \n            \"The Fault in Our Stars\", \"Pride and Prejudice\"),\n  author = c(\"Suzanne Collins\", \"George Orwell\", \"Harper Lee\", \n             \"John Green\", \"Jane Austen\"),\n  year_published = c(2008, 1949, 1960, 2012, 1813),\n  pages = c(374, 328, 281, 313, 432),\n  stringsAsFactors = FALSE\n)\n\n# Display the original data frame\nprint(\"All books:\")\n\n[1] \"All books:\"\n\nprint(books)\n\n                   title          author year_published pages\n1       The Hunger Games Suzanne Collins           2008   374\n2                   1984   George Orwell           1949   328\n3  To Kill a Mockingbird      Harper Lee           1960   281\n4 The Fault in Our Stars      John Green           2012   313\n5    Pride and Prejudice     Jane Austen           1813   432\n\n# Filter for books published after 2000\nrecent_books &lt;- books[books$year_published &gt; 2000, ]\nprint(\"Books published after 2000:\")\n\n[1] \"Books published after 2000:\"\n\nprint(recent_books)\n\n                   title          author year_published pages\n1       The Hunger Games Suzanne Collins           2008   374\n4 The Fault in Our Stars      John Green           2012   313\n\n# Calculate average number of pages for recent books\navg_pages_recent &lt;- mean(recent_books$pages)\nprint(paste(\"Average number of pages for books published after 2000:\", \n            round(avg_pages_recent, 1)))\n\n[1] \"Average number of pages for books published after 2000: 343.5\"\n\n\nThe books published after 2000 are: - The Hunger Games (2008) - 374 pages - The Fault in Our Stars (2012) - 313 pages\nThe average number of pages for books published after 2000 is 343.5 pages."
  },
  {
    "objectID": "assignments/Lab One Part Two - Edited.html",
    "href": "assignments/Lab One Part Two - Edited.html",
    "title": "Part 2: Data Analysis, Visualization, and Programming",
    "section": "",
    "text": "By the end of this lab, you will be able to: - Use advanced data manipulation techniques with tidyverse packages - Create sophisticated visualizations with ggplot2 - Perform statistical analyses using modern R approaches - Apply functional programming concepts with purrr - Integrate multiple R packages for comprehensive data analysis\n\n\n\n\n\nBefore diving into advanced data analysis, let‚Äôs learn how to install and use R packages. Packages extend R‚Äôs functionality significantly.\n\n\n\n\nCode\n# Install individual packages\ninstall.packages(\"tidyverse\")  # A collection of data science packages\ninstall.packages(\"dplyr\")      # Data manipulation\ninstall.packages(\"ggplot2\")    # Advanced plotting\ninstall.packages(\"readr\")      # Reading data files\ninstall.packages(\"tidyr\")      # Data reshaping\n\n# Install multiple packages at once\npackages_to_install &lt;- c(\"lubridate\", \"stringr\", \"forcats\", \"purrr\")\ninstall.packages(packages_to_install)\n\n# Install from CRAN (most common)\ninstall.packages(\"plotly\")     # Interactive plots\ninstall.packages(\"corrplot\")   # Correlation plots\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nInstalling packages...\n\n\nPackage 'tidyverse' successfully installed\n\n\nPackage 'dplyr' successfully installed\n\n\nPackage 'ggplot2' successfully installed\n\n\n\n\n\n\n\n\n\n\nCode\n# Load libraries for this session\nlibrary(tidyverse)  # Loads dplyr, ggplot2, readr, tibble, stringr, forcats\nlibrary(dplyr)      # Data manipulation\nlibrary(ggplot2)    # Grammar of graphics plotting\n\n# Alternative method\nrequire(tidyverse)  # Similar to library() but returns TRUE/FALSE\n\n# Check if package is installed before loading\nif (!require(tidyverse)) {\n  install.packages(\"tidyverse\")\n  library(tidyverse)\n}\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.5.2     ‚úî purrr   0.3.5\n‚úî tibble  3.1.8     ‚úî dplyr   1.1.0\n‚úî tidyr   1.2.1     ‚úî stringr 1.5.0\n‚úî readr   2.1.3     ‚úî forcats 0.5.2\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\n\n\n\n\n\n\n\n\nCode\n# Check installed packages\ninstalled.packages()[1:5, c(\"Package\", \"Version\")]\n\n# Update packages\nupdate.packages()\n\n# Check which packages are loaded\nsearch()\n\n# Get help for a package\nhelp(package = \"dplyr\")\n\n# See package version\npackageVersion(\"dplyr\")\n\n# Detach a package if needed\ndetach(\"package:dplyr\", unload = TRUE)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nLoaded packages:\n\n\n[1] \".GlobalEnv\"     \"package:dplyr\"    \"package:ggplot2\"  \n\n\n[4] \"package:stats\"   \"package:graphics\" \"package:utils\"    \n\n\n\nPackage version example:\n\n\ndplyr: 1.1.0\n\n\n\n\n\n\n\n\n\nNow let‚Äôs explore data using modern R techniques with tidyverse packages.\n\n\n\n\nCode\n# Load datasets (assuming tidyverse is loaded)\ndata(iris)\ndata(mtcars)\n\n# Convert to tibbles (modern data frames)\niris_tbl &lt;- as_tibble(iris)\nmtcars_tbl &lt;- as_tibble(mtcars, rownames = \"car_name\")\n\n# Explore with tidyverse functions\nglimpse(iris_tbl)\nglimpse(mtcars_tbl)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.‚Ä¶\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.‚Ä¶\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.‚Ä¶\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.‚Ä¶\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s‚Ä¶\n\n\nRows: 32\nColumns: 12\n$ car_name &lt;chr&gt; \"Mazda RX4\", \"Mazda RX4 Wag\", \"Datsun 710\", \"Hornet 4 Drive\",‚Ä¶\n$ mpg      &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 1‚Ä¶\n$ cyl      &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4‚Ä¶\n$ disp     &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8‚Ä¶\n$ hp       &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180,‚Ä¶\n$ drat     &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3‚Ä¶\n$ wt       &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150‚Ä¶\n$ qsec     &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90‚Ä¶\n$ vs       &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1‚Ä¶\n$ am       &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0‚Ä¶\n$ gear     &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3‚Ä¶\n$ carb     &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1‚Ä¶\n\n\n\n\n\n\n\n\n\n\nCode\n# dplyr verbs for data manipulation\n\n# select() - choose columns\niris_tbl %&gt;%\n  select(Species, Sepal.Length, Sepal.Width) %&gt;%\n  head()\n\n# filter() - choose rows\niris_tbl %&gt;%\n  filter(Species == \"setosa\", Sepal.Length &gt; 5) %&gt;%\n  head()\n\n# mutate() - create new columns\niris_tbl %&gt;%\n  mutate(\n    Sepal.Ratio = Sepal.Length / Sepal.Width,\n    Size.Category = if_else(Sepal.Length &gt; median(Sepal.Length),\n                            \"Large\", \"Small\")\n  ) %&gt;%\n  head()\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 6 √ó 3\n  Species Sepal.Length Sepal.Width\n  &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 setosa           5.1         3.5\n2 setosa           4.9         3  \n3 setosa           4.7         3.2\n4 setosa           4.6         3.1\n5 setosa           5           3.6\n6 setosa           5.4         3.9\n\n\n# A tibble: 6 √ó 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5          1.4         0.2 setosa \n2          5.4         3.9          1.7         0.4 setosa \n3          5.4         3.7          1.5         0.2 setosa \n4          5.8         4            1.2         0.2 setosa \n5          5.7         4.4          1.5         0.4 setosa \n6          5.4         3.9          1.3         0.4 setosa \n\n\n# A tibble: 6 √ó 7\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Ratio Size.C‚Ä¶¬π\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt; &lt;chr&gt;   \n1          5.1         3.5          1.4         0.2 setosa         1.46 Small   \n2          4.9         3            1.4         0.2 setosa         1.63 Small   \n3          4.7         3.2          1.3         0.2 setosa         1.47 Small   \n4          4.6         3.1          1.5         0.2 setosa         1.48 Small   \n5          5           3.6          1.4         0.2 setosa         1.39 Small   \n6          5.4         3.9          1.7         0.4 setosa         1.38 Small   \n# ‚Ä¶ with abbreviated variable name ¬π‚ÄãSize.Category\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by and summarize\niris_summary &lt;- iris_tbl %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    n = n(),\n    mean_sepal_length = mean(Sepal.Length),\n    sd_sepal_length = sd(Sepal.Length),\n    median_sepal_width = median(Sepal.Width),\n    min_petal_length = min(Petal.Length),\n    max_petal_length = max(Petal.Length),\n    .groups = \"drop\"\n  )\nprint(iris_summary)\n\n# More complex grouping\nmtcars_summary &lt;- mtcars_tbl %&gt;%\n  group_by(cyl, gear) %&gt;%\n  summarise(\n    count = n(),\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(avg_mpg))\nprint(mtcars_summary)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 3 √ó 7\n  Species        n mean_sepal_length sd_sepal_length median_se‚Ä¶¬π min_p‚Ä¶¬≤ max_p‚Ä¶¬≥\n  &lt;fct&gt;      &lt;int&gt;             &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 setosa        50              5.01           0.352         3.4     1       1.9\n2 versicolor    50              5.94           0.516         2.8     3       5.1\n3 virginica     50              6.59           0.636         3       4.5     6.9\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãmedian_sepal_width, ¬≤‚Äãmin_petal_length,\n#   ¬≥‚Äãmax_petal_length\n\n\n# A tibble: 8 √ó 5\n    cyl  gear count avg_mpg avg_hp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     4     5     2    28.2   102 \n2     4     4     8    26.9    76 \n3     4     3     1    21.5    97 \n4     6     3     2    19.8   108.\n5     6     4     4    19.8   116.\n6     6     5     1    19.7   175 \n7     8     5     2    15.4   300.\n8     8     3    12    15.0   194.\n\n\n\n\n\n\n\n\n\nggplot2 provides a powerful grammar of graphics for creating sophisticated visualizations.\n\n\n\n\nCode\n# Basic ggplot structure\n# ggplot(data) + geom_function() + aesthetics + themes\n\n# Simple histogram\nggplot(iris_tbl, aes(x = Sepal.Length)) +\n  geom_histogram(bins = 20, fill = \"lightblue\", color = \"darkblue\", alpha = 0.7) +\n  geom_vline(aes(xintercept = mean(Sepal.Length)),\n             color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribution of Sepal Length\",\n    subtitle = \"Iris Dataset\",\n    x = \"Sepal Length (cm)\",\n    y = \"Frequency\",\n    caption = \"Red line shows mean value\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Scatter plot with facets and regression lines\nggplot(iris_tbl, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  facet_wrap(~ Species, ncol = 3) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Sepal Length vs Width by Species\",\n    x = \"Sepal Length (cm)\",\n    y = \"Sepal Width (cm)\"\n  ) +\n  theme_bw() +\n  theme(\n    plot.title = element_text(size = 16, hjust = 0.5),\n    strip.text = element_text(size = 12, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs perform statistical analyses using both base R and tidyverse approaches.\n\n\n\n\nCode\n# Modern approach with dplyr\niris_stats &lt;- iris_tbl %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    across(where(is.numeric),\n           list(mean = mean,\n                median = median,\n                sd = sd,\n                min = min,\n                max = max,\n               q25 = ~quantile(.x, 0.25),\n               q75 = ~quantile(.x, 0.75)),\n           .names = \"{.col}_{.fn}\"),\n    .groups = \"drop\"\n  )\nprint(iris_stats)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 3 √ó 29\n  Species    Sepal.Len‚Ä¶¬π Sepal‚Ä¶¬≤ Sepal‚Ä¶¬≥ Sepal‚Ä¶‚Å¥ Sepal‚Ä¶‚Åµ Sepal‚Ä¶‚Å∂ Sepal‚Ä¶‚Å∑ Sepal‚Ä¶‚Å∏\n  &lt;fct&gt;            &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 setosa            5.01     5     0.352     4.3     5.8    4.8      5.2    3.43\n2 versicolor        5.94     5.9   0.516     4.9     7      5.6      6.3    2.77\n3 virginica         6.59     6.5   0.636     4.9     7.9    6.22     6.9    2.97\n# ‚Ä¶ with 20 more variables: Sepal.Width_median &lt;dbl&gt;, Sepal.Width_sd &lt;dbl&gt;,\n#   Sepal.Width_min &lt;dbl&gt;, Sepal.Width_max &lt;dbl&gt;, Sepal.Width_q25 &lt;dbl&gt;,\n#   Sepal.Width_q75 &lt;dbl&gt;, Petal.Length_mean &lt;dbl&gt;, Petal.Length_median &lt;dbl&gt;,\n#   Petal.Length_sd &lt;dbl&gt;, Petal.Length_min &lt;dbl&gt;, Petal.Length_max &lt;dbl&gt;,\n#   Petal.Length_q25 &lt;dbl&gt;, Petal.Length_q75 &lt;dbl&gt;, Petal.Width_mean &lt;dbl&gt;,\n#   Petal.Width_median &lt;dbl&gt;, Petal.Width_sd &lt;dbl&gt;, Petal.Width_min &lt;dbl&gt;,\n#   Petal.Width_max &lt;dbl&gt;, Petal.Width_q25 &lt;dbl&gt;, Petal.Width_q75 &lt;dbl&gt;, and ‚Ä¶\n\n\n\n\n\n\n\n\n\n\nCode\n# T-tests with tidy output\nt_test_results &lt;- iris_tbl %&gt;%\n  filter(Species %in% c(\"setosa\", \"versicolor\")) %&gt;%\n  t.test(Sepal.Length ~ Species, data = .)\nprint(t_test_results)\n\n# ANOVA with tidy output\nanova_results &lt;- aov(Sepal.Length ~ Species, data = iris_tbl)\nprint(summary(anova_results))\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -10.521, df = 86.538, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group setosa and group versicolor is not equal to 0\n95 percent confidence interval:\n -1.1057074 -0.7542926\nsample estimates:\n    mean in group setosa mean in group versicolor \n                   5.006                    5.936 \n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\nCode\n# Linear modeling\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars_tbl)\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars_tbl)\n\n# Compare models\nsummary(model1)\nsummary(model2)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars_tbl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\n\nCall:\nlm(formula = mpg ~ wt + hp + cyl, data = mtcars_tbl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9290 -1.5598 -0.5311  1.1850  5.8986 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***\nwt          -3.16697    0.74058  -4.276 0.000199 ***\nhp          -0.01804    0.01188  -1.519 0.140015    \ncyl         -0.94162    0.55092  -1.709 0.098480 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.512 on 28 degrees of freedom\nMultiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 \nF-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Apply function to multiple columns\niris_tbl %&gt;%\n  select(where(is.numeric)) %&gt;%\n  map(mean)\n\n# Map with different output types\niris_tbl %&gt;%\n  select(where(is.numeric)) %&gt;%\n  map_dbl(sd)\n\n# Map over groups\niris_tbl %&gt;%\n  split(.$Species) %&gt;%\n  map(~lm(Sepal.Length ~ Sepal.Width, data = .x)) %&gt;%\n  map_dbl(~summary(.x)$r.squared)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n$Sepal.Length\n[1] 5.843333\n\n$Sepal.Width\n[1] 3.057333\n\n$Petal.Length\n[1] 3.758\n\n$Petal.Width\n[1] 1.199333\n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.8280661    0.4358663    1.7652982    0.7622377 \n\n\n    setosa versicolor  virginica \n 0.5513756  0.2765821  0.2090573 \n\n\n\n\n\n\n\n\n\n\n\nExercise 1: Using tidyverse functions, create a comprehensive analysis of the mtcars dataset that includes: - A summary of fuel efficiency (mpg) by number of cylinders - A scatter plot showing the relationship between weight and mpg, colored by cylinders - Create a new categorical variable for car efficiency (High: &gt;20 mpg, Medium: 15-20 mpg, Low: &lt;15 mpg) - Calculate the correlation between mpg and all other numeric variables\n\n\n\n\n\n\nClick to see Exercise 1 Answer\n\n\n\n\n\nManual Answer Summary: - 4-cylinder cars have the highest average MPG (26.7) - 8-cylinder cars have the lowest average MPG (15.1)\n- Weight shows the strongest negative correlation with MPG (-0.868) - Number of cylinders also strongly negatively correlates with MPG (-0.852) - Most cars fall into the Medium efficiency category (15-20 mpg)"
  },
  {
    "objectID": "assignments/Lab One Part Two - Edited.html#part-2-data-analysis-visualization-and-programming",
    "href": "assignments/Lab One Part Two - Edited.html#part-2-data-analysis-visualization-and-programming",
    "title": "Part 2: Data Analysis, Visualization, and Programming",
    "section": "",
    "text": "Before diving into advanced data analysis, let‚Äôs learn how to install and use R packages. Packages extend R‚Äôs functionality significantly.\n\n\n\n\nCode\n# Install individual packages\ninstall.packages(\"tidyverse\")  # A collection of data science packages\ninstall.packages(\"dplyr\")      # Data manipulation\ninstall.packages(\"ggplot2\")    # Advanced plotting\ninstall.packages(\"readr\")      # Reading data files\ninstall.packages(\"tidyr\")      # Data reshaping\n\n# Install multiple packages at once\npackages_to_install &lt;- c(\"lubridate\", \"stringr\", \"forcats\", \"purrr\")\ninstall.packages(packages_to_install)\n\n# Install from CRAN (most common)\ninstall.packages(\"plotly\")     # Interactive plots\ninstall.packages(\"corrplot\")   # Correlation plots\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nInstalling packages...\n\n\nPackage 'tidyverse' successfully installed\n\n\nPackage 'dplyr' successfully installed\n\n\nPackage 'ggplot2' successfully installed\n\n\n\n\n\n\n\n\n\n\nCode\n# Load libraries for this session\nlibrary(tidyverse)  # Loads dplyr, ggplot2, readr, tibble, stringr, forcats\nlibrary(dplyr)      # Data manipulation\nlibrary(ggplot2)    # Grammar of graphics plotting\n\n# Alternative method\nrequire(tidyverse)  # Similar to library() but returns TRUE/FALSE\n\n# Check if package is installed before loading\nif (!require(tidyverse)) {\n  install.packages(\"tidyverse\")\n  library(tidyverse)\n}\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.5.2     ‚úî purrr   0.3.5\n‚úî tibble  3.1.8     ‚úî dplyr   1.1.0\n‚úî tidyr   1.2.1     ‚úî stringr 1.5.0\n‚úî readr   2.1.3     ‚úî forcats 0.5.2\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\n\n\n\n\n\n\n\n\n\nCode\n# Check installed packages\ninstalled.packages()[1:5, c(\"Package\", \"Version\")]\n\n# Update packages\nupdate.packages()\n\n# Check which packages are loaded\nsearch()\n\n# Get help for a package\nhelp(package = \"dplyr\")\n\n# See package version\npackageVersion(\"dplyr\")\n\n# Detach a package if needed\ndetach(\"package:dplyr\", unload = TRUE)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nLoaded packages:\n\n\n[1] \".GlobalEnv\"     \"package:dplyr\"    \"package:ggplot2\"  \n\n\n[4] \"package:stats\"   \"package:graphics\" \"package:utils\"    \n\n\n\nPackage version example:\n\n\ndplyr: 1.1.0\n\n\n\n\n\n\n\n\n\nNow let‚Äôs explore data using modern R techniques with tidyverse packages.\n\n\n\n\nCode\n# Load datasets (assuming tidyverse is loaded)\ndata(iris)\ndata(mtcars)\n\n# Convert to tibbles (modern data frames)\niris_tbl &lt;- as_tibble(iris)\nmtcars_tbl &lt;- as_tibble(mtcars, rownames = \"car_name\")\n\n# Explore with tidyverse functions\nglimpse(iris_tbl)\nglimpse(mtcars_tbl)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.‚Ä¶\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.‚Ä¶\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.‚Ä¶\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.‚Ä¶\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s‚Ä¶\n\n\nRows: 32\nColumns: 12\n$ car_name &lt;chr&gt; \"Mazda RX4\", \"Mazda RX4 Wag\", \"Datsun 710\", \"Hornet 4 Drive\",‚Ä¶\n$ mpg      &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 1‚Ä¶\n$ cyl      &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4‚Ä¶\n$ disp     &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8‚Ä¶\n$ hp       &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180,‚Ä¶\n$ drat     &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3‚Ä¶\n$ wt       &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150‚Ä¶\n$ qsec     &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90‚Ä¶\n$ vs       &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1‚Ä¶\n$ am       &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0‚Ä¶\n$ gear     &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3‚Ä¶\n$ carb     &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1‚Ä¶\n\n\n\n\n\n\n\n\n\n\nCode\n# dplyr verbs for data manipulation\n\n# select() - choose columns\niris_tbl %&gt;%\n  select(Species, Sepal.Length, Sepal.Width) %&gt;%\n  head()\n\n# filter() - choose rows\niris_tbl %&gt;%\n  filter(Species == \"setosa\", Sepal.Length &gt; 5) %&gt;%\n  head()\n\n# mutate() - create new columns\niris_tbl %&gt;%\n  mutate(\n    Sepal.Ratio = Sepal.Length / Sepal.Width,\n    Size.Category = if_else(Sepal.Length &gt; median(Sepal.Length),\n                            \"Large\", \"Small\")\n  ) %&gt;%\n  head()\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 6 √ó 3\n  Species Sepal.Length Sepal.Width\n  &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 setosa           5.1         3.5\n2 setosa           4.9         3  \n3 setosa           4.7         3.2\n4 setosa           4.6         3.1\n5 setosa           5           3.6\n6 setosa           5.4         3.9\n\n\n# A tibble: 6 √ó 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5          1.4         0.2 setosa \n2          5.4         3.9          1.7         0.4 setosa \n3          5.4         3.7          1.5         0.2 setosa \n4          5.8         4            1.2         0.2 setosa \n5          5.7         4.4          1.5         0.4 setosa \n6          5.4         3.9          1.3         0.4 setosa \n\n\n# A tibble: 6 √ó 7\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.Ratio Size.C‚Ä¶¬π\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt; &lt;chr&gt;   \n1          5.1         3.5          1.4         0.2 setosa         1.46 Small   \n2          4.9         3            1.4         0.2 setosa         1.63 Small   \n3          4.7         3.2          1.3         0.2 setosa         1.47 Small   \n4          4.6         3.1          1.5         0.2 setosa         1.48 Small   \n5          5           3.6          1.4         0.2 setosa         1.39 Small   \n6          5.4         3.9          1.7         0.4 setosa         1.38 Small   \n# ‚Ä¶ with abbreviated variable name ¬π‚ÄãSize.Category\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by and summarize\niris_summary &lt;- iris_tbl %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    n = n(),\n    mean_sepal_length = mean(Sepal.Length),\n    sd_sepal_length = sd(Sepal.Length),\n    median_sepal_width = median(Sepal.Width),\n    min_petal_length = min(Petal.Length),\n    max_petal_length = max(Petal.Length),\n    .groups = \"drop\"\n  )\nprint(iris_summary)\n\n# More complex grouping\nmtcars_summary &lt;- mtcars_tbl %&gt;%\n  group_by(cyl, gear) %&gt;%\n  summarise(\n    count = n(),\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(desc(avg_mpg))\nprint(mtcars_summary)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 3 √ó 7\n  Species        n mean_sepal_length sd_sepal_length median_se‚Ä¶¬π min_p‚Ä¶¬≤ max_p‚Ä¶¬≥\n  &lt;fct&gt;      &lt;int&gt;             &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 setosa        50              5.01           0.352         3.4     1       1.9\n2 versicolor    50              5.94           0.516         2.8     3       5.1\n3 virginica     50              6.59           0.636         3       4.5     6.9\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãmedian_sepal_width, ¬≤‚Äãmin_petal_length,\n#   ¬≥‚Äãmax_petal_length\n\n\n# A tibble: 8 √ó 5\n    cyl  gear count avg_mpg avg_hp\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     4     5     2    28.2   102 \n2     4     4     8    26.9    76 \n3     4     3     1    21.5    97 \n4     6     3     2    19.8   108.\n5     6     4     4    19.8   116.\n6     6     5     1    19.7   175 \n7     8     5     2    15.4   300.\n8     8     3    12    15.0   194.\n\n\n\n\n\n\n\n\n\nggplot2 provides a powerful grammar of graphics for creating sophisticated visualizations.\n\n\n\n\nCode\n# Basic ggplot structure\n# ggplot(data) + geom_function() + aesthetics + themes\n\n# Simple histogram\nggplot(iris_tbl, aes(x = Sepal.Length)) +\n  geom_histogram(bins = 20, fill = \"lightblue\", color = \"darkblue\", alpha = 0.7) +\n  geom_vline(aes(xintercept = mean(Sepal.Length)),\n             color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribution of Sepal Length\",\n    subtitle = \"Iris Dataset\",\n    x = \"Sepal Length (cm)\",\n    y = \"Frequency\",\n    caption = \"Red line shows mean value\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Scatter plot with facets and regression lines\nggplot(iris_tbl, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  facet_wrap(~ Species, ncol = 3) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Sepal Length vs Width by Species\",\n    x = \"Sepal Length (cm)\",\n    y = \"Sepal Width (cm)\"\n  ) +\n  theme_bw() +\n  theme(\n    plot.title = element_text(size = 16, hjust = 0.5),\n    strip.text = element_text(size = 12, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs perform statistical analyses using both base R and tidyverse approaches.\n\n\n\n\nCode\n# Modern approach with dplyr\niris_stats &lt;- iris_tbl %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    across(where(is.numeric),\n           list(mean = mean,\n                median = median,\n                sd = sd,\n                min = min,\n                max = max,\n               q25 = ~quantile(.x, 0.25),\n               q75 = ~quantile(.x, 0.75)),\n           .names = \"{.col}_{.fn}\"),\n    .groups = \"drop\"\n  )\nprint(iris_stats)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n# A tibble: 3 √ó 29\n  Species    Sepal.Len‚Ä¶¬π Sepal‚Ä¶¬≤ Sepal‚Ä¶¬≥ Sepal‚Ä¶‚Å¥ Sepal‚Ä¶‚Åµ Sepal‚Ä¶‚Å∂ Sepal‚Ä¶‚Å∑ Sepal‚Ä¶‚Å∏\n  &lt;fct&gt;            &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 setosa            5.01     5     0.352     4.3     5.8    4.8      5.2    3.43\n2 versicolor        5.94     5.9   0.516     4.9     7      5.6      6.3    2.77\n3 virginica         6.59     6.5   0.636     4.9     7.9    6.22     6.9    2.97\n# ‚Ä¶ with 20 more variables: Sepal.Width_median &lt;dbl&gt;, Sepal.Width_sd &lt;dbl&gt;,\n#   Sepal.Width_min &lt;dbl&gt;, Sepal.Width_max &lt;dbl&gt;, Sepal.Width_q25 &lt;dbl&gt;,\n#   Sepal.Width_q75 &lt;dbl&gt;, Petal.Length_mean &lt;dbl&gt;, Petal.Length_median &lt;dbl&gt;,\n#   Petal.Length_sd &lt;dbl&gt;, Petal.Length_min &lt;dbl&gt;, Petal.Length_max &lt;dbl&gt;,\n#   Petal.Length_q25 &lt;dbl&gt;, Petal.Length_q75 &lt;dbl&gt;, Petal.Width_mean &lt;dbl&gt;,\n#   Petal.Width_median &lt;dbl&gt;, Petal.Width_sd &lt;dbl&gt;, Petal.Width_min &lt;dbl&gt;,\n#   Petal.Width_max &lt;dbl&gt;, Petal.Width_q25 &lt;dbl&gt;, Petal.Width_q75 &lt;dbl&gt;, and ‚Ä¶\n\n\n\n\n\n\n\n\n\n\nCode\n# T-tests with tidy output\nt_test_results &lt;- iris_tbl %&gt;%\n  filter(Species %in% c(\"setosa\", \"versicolor\")) %&gt;%\n  t.test(Sepal.Length ~ Species, data = .)\nprint(t_test_results)\n\n# ANOVA with tidy output\nanova_results &lt;- aov(Sepal.Length ~ Species, data = iris_tbl)\nprint(summary(anova_results))\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -10.521, df = 86.538, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group setosa and group versicolor is not equal to 0\n95 percent confidence interval:\n -1.1057074 -0.7542926\nsample estimates:\n    mean in group setosa mean in group versicolor \n                   5.006                    5.936 \n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\nCode\n# Linear modeling\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars_tbl)\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars_tbl)\n\n# Compare models\nsummary(model1)\nsummary(model2)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars_tbl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\n\nCall:\nlm(formula = mpg ~ wt + hp + cyl, data = mtcars_tbl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9290 -1.5598 -0.5311  1.1850  5.8986 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***\nwt          -3.16697    0.74058  -4.276 0.000199 ***\nhp          -0.01804    0.01188  -1.519 0.140015    \ncyl         -0.94162    0.55092  -1.709 0.098480 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.512 on 28 degrees of freedom\nMultiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 \nF-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Apply function to multiple columns\niris_tbl %&gt;%\n  select(where(is.numeric)) %&gt;%\n  map(mean)\n\n# Map with different output types\niris_tbl %&gt;%\n  select(where(is.numeric)) %&gt;%\n  map_dbl(sd)\n\n# Map over groups\niris_tbl %&gt;%\n  split(.$Species) %&gt;%\n  map(~lm(Sepal.Length ~ Sepal.Width, data = .x)) %&gt;%\n  map_dbl(~summary(.x)$r.squared)\n\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n$Sepal.Length\n[1] 5.843333\n\n$Sepal.Width\n[1] 3.057333\n\n$Petal.Length\n[1] 3.758\n\n$Petal.Width\n[1] 1.199333\n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.8280661    0.4358663    1.7652982    0.7622377 \n\n\n    setosa versicolor  virginica \n 0.5513756  0.2765821  0.2090573"
  },
  {
    "objectID": "assignments/Lab One Part Two - Edited.html#practice-exercises",
    "href": "assignments/Lab One Part Two - Edited.html#practice-exercises",
    "title": "Part 2: Data Analysis, Visualization, and Programming",
    "section": "",
    "text": "Exercise 1: Using tidyverse functions, create a comprehensive analysis of the mtcars dataset that includes: - A summary of fuel efficiency (mpg) by number of cylinders - A scatter plot showing the relationship between weight and mpg, colored by cylinders - Create a new categorical variable for car efficiency (High: &gt;20 mpg, Medium: 15-20 mpg, Low: &lt;15 mpg) - Calculate the correlation between mpg and all other numeric variables\n\n\n\n\n\n\nClick to see Exercise 1 Answer\n\n\n\n\n\nManual Answer Summary: - 4-cylinder cars have the highest average MPG (26.7) - 8-cylinder cars have the lowest average MPG (15.1)\n- Weight shows the strongest negative correlation with MPG (-0.868) - Number of cylinders also strongly negatively correlates with MPG (-0.852) - Most cars fall into the Medium efficiency category (15-20 mpg)"
  },
  {
    "objectID": "assignments/projects.html",
    "href": "assignments/projects.html",
    "title": "Projects",
    "section": "",
    "text": "Due: [DATE]\nLength: [PAGE COUNT/REQUIREMENTS]\nGoal: [PROJECT OBJECTIVE]\n\n\n\n[REQUIREMENT 1]\n[REQUIREMENT 2]\n[REQUIREMENT 3]\n\n\n\n\n\n[CRITERION 1] ([%])\n[CRITERION 2] ([%])\n[CRITERION 3] ([%])"
  },
  {
    "objectID": "assignments/projects.html#project-name-1",
    "href": "assignments/projects.html#project-name-1",
    "title": "Projects",
    "section": "",
    "text": "Due: [DATE]\nLength: [PAGE COUNT/REQUIREMENTS]\nGoal: [PROJECT OBJECTIVE]\n\n\n\n[REQUIREMENT 1]\n[REQUIREMENT 2]\n[REQUIREMENT 3]\n\n\n\n\n\n[CRITERION 1] ([%])\n[CRITERION 2] ([%])\n[CRITERION 3] ([%])"
  },
  {
    "objectID": "assignments/projects.html#project-name-2",
    "href": "assignments/projects.html#project-name-2",
    "title": "Projects",
    "section": "[PROJECT NAME 2]",
    "text": "[PROJECT NAME 2]\nDue: [DATE]\nLength: [PAGE COUNT/REQUIREMENTS]\nGoal: [PROJECT OBJECTIVE]\n\nTimeline\n\n[MILESTONE 1]: [DATE]\n[MILESTONE 2]: [DATE]\n[FINAL DUE DATE]: [DATE]\n\n\n\nRequirements\n\n[REQUIREMENT 1]\n[REQUIREMENT 2]\n[REQUIREMENT 3]\n\n\n\nGrading Criteria\n\n[CRITERION 1] ([%])\n[CRITERION 2] ([%])\n[CRITERION 3] ([%])"
  },
  {
    "objectID": "assignments/projects.html#project-ideas",
    "href": "assignments/projects.html#project-ideas",
    "title": "Projects",
    "section": "Project Ideas",
    "text": "Project Ideas\n\n\nSuggested Topics\n\n[TOPIC 1]\n[TOPIC 2]\n[TOPIC 3]\n\n\n\nData Sources\n\n[DATA SOURCE 1]\n[DATA SOURCE 2]\n[DATA SOURCE 3]"
  },
  {
    "objectID": "assignments/Lab One Part Two.html",
    "href": "assignments/Lab One Part Two.html",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "Let‚Äôs work with R‚Äôs built-in datasets and explore more advanced data manipulation techniques.\n\n\n\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\n\n\n\n\n\n\n\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.8280661    0.4358663    1.7652982    0.7622377 \n\n\n     Sepal.Length Sepal.Width Petal.Length Petal.Width\n[1,]          4.3         2.0          1.0         0.1\n[2,]          7.9         4.4          6.9         2.5\n\n\n\n\n\n\n\n\n\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\n\n   \n     3  4  5\n  4  1  8  2\n  6  2  4  1\n  8 12  0  2\n\n\n   \n             3          4          5\n  4 0.09090909 0.72727273 0.18181818\n  6 0.28571429 0.57142857 0.14285714\n  8 0.85714286 0.00000000 0.14285714\n\n\n\n\n\n\n\n\n\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Large setosa flowers:\"\n\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n11          5.4         3.7          1.5         0.2  setosa\n15          5.8         4.0          1.2         0.2  setosa\n16          5.7         4.4          1.5         0.4  setosa\n17          5.4         3.9          1.3         0.4  setosa\n18          5.1         3.5          1.4         0.3  setosa\n19          5.7         3.8          1.7         0.3  setosa\n20          5.1         3.8          1.5         0.3  setosa\n21          5.4         3.4          1.7         0.2  setosa\n22          5.1         3.7          1.5         0.4  setosa\n24          5.1         3.3          1.7         0.5  setosa\n28          5.2         3.5          1.5         0.2  setosa\n29          5.2         3.4          1.4         0.2  setosa\n32          5.4         3.4          1.5         0.4  setosa\n33          5.2         4.1          1.5         0.1  setosa\n34          5.5         4.2          1.4         0.2  setosa\n37          5.5         3.5          1.3         0.2  setosa\n40          5.1         3.4          1.5         0.2  setosa\n45          5.1         3.8          1.9         0.4  setosa\n47          5.1         3.8          1.6         0.2  setosa\n49          5.3         3.7          1.5         0.2  setosa\n\n\n[1] \"Efficient and powerful cars:\"\n\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\n\n\n\n\n\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\n# Aggregating data\n# Average measurements by species\naggregate(. ~ Species, data = iris, FUN = mean)\n\n# Multiple statistics\naggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Random sample of iris data:\"\n\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n109          6.7         2.5          5.8         1.8  virginica\n79           6.0         2.9          4.5         1.5 versicolor\n106          7.6         3.0          6.6         2.1  virginica\n9            4.4         2.9          1.4         0.2     setosa\n33           5.2         4.1          1.5         0.1     setosa\n31           4.8         3.1          1.6         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n114          5.7         2.5          5.0         2.0  virginica\n60           5.2         2.7          3.9         1.4 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n\n\n[1] \"Average measurements by species:\"\n\n\n     Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1     setosa        5.006       3.428        1.462       0.246\n2 versicolor        5.936       2.770        4.260       1.326\n3  virginica        6.588       2.974        5.552       2.026\n\n\n[1] \"MPG and HP statistics by cylinder:\"\n\n\n  cyl  mpg.mean    mpg.sd   hp.mean     hp.sd\n1   4 26.663636  4.509828  82.63636  20.93453\n2   6 19.742857  1.453567 122.28571  24.26049\n3   8 15.100000  2.560048 209.21429  50.97689\n\n\n\n\n\n\n\n\n\nR‚Äôs plotting capabilities are extensive. Let‚Äôs explore various types of plots.\n\n\n\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs perform various statistical tests and create models.\n\n\n\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     mean    median        sd       min       max   q25.25%   q75.75% \n5.8433333 5.8000000 0.8280661 4.3000000 7.9000000 5.1000000 6.4000000 \n\n\n\n\n\n\n\n\n\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\n\n\n\n\n\n\n\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  setosa_sepal and versicolor_sepal\nt = -10.521, df = 86.538, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.1057074 -0.7542926\nsample estimates:\nmean of x mean of y \n    5.006     5.936 \n\n\n\n\n\n\n\n\n\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0\n\n\n\n\n\n\n\n\n\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\n\n\n\n\n\n\n\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt + hp + cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9290 -1.5598 -0.5311  1.1850  5.8986 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***\nwt          -3.16697    0.74058  -4.276 0.000199 ***\nhp          -0.01804    0.01188  -1.519 0.140015    \ncyl         -0.94162    0.55092  -1.709 0.098480 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.512 on 28 degrees of freedom\nMultiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 \nF-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11\n\n\nAnalysis of Variance Table\n\nModel 1: mpg ~ wt\nModel 2: mpg ~ wt + hp + cyl\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   \n1     30 278.32                                \n2     28 176.62  2     101.7 8.0615 0.001718 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] \"Predicted MPG: 20.9\"\n\n\n\n\n\n\n\n\n\nLearning to write functions and use control structures makes R much more powerful.\n\n\n\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"B\"\n\n\n[1] \"A\"\n\n\n\n\n\n\n\n\n\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"A\" \"B\" \"C\" \"D\" \"F\"\n\n\n\n\n\n\n\n\n\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n [1]  0  1  1  2  3  5  8 13 21 34\n\n\n\n\n\n\n\n\n\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5 4 3 2 1\n\n\n\n\n\n\n\n\n\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n$a\n[1] 3\n\n$b\n[1] 8\n\n$c\n[1] 13\n\n\n a  b  c \n 3  8 13 \n\n\n[1] 5 7 9\n\n\n\n\n\nüîç Exercise 2a: Create a function that calculates the coefficient of variation (CV = sd/mean) for a numeric vector. Test it on the Sepal.Length column of the iris dataset for each species.\n\n\n\n\n\n\nClick to see Exercise 2a Answer\n\n\n\n\n\n\n# Create coefficient of variation function\ncoeff_variation &lt;- function(x) {\n  cv &lt;- sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\n  return(cv)\n}\n\n# Test on Sepal.Length for each species\nspecies_list &lt;- levels(iris$Species)\ncv_results &lt;- sapply(species_list, function(species) {\n  species_data &lt;- iris[iris$Species == species, \"Sepal.Length\"]\n  coeff_variation(species_data)\n})\n\nprint(\"Coefficient of Variation for Sepal.Length by Species:\")\n\n[1] \"Coefficient of Variation for Sepal.Length by Species:\"\n\nprint(round(cv_results, 4))\n\n    setosa versicolor  virginica \n    0.0704     0.0870     0.0965 \n\n# Alternative approach using aggregate\ncv_by_species &lt;- aggregate(Sepal.Length ~ Species, data = iris, \n                          FUN = function(x) sd(x)/mean(x))\nprint(\"Using aggregate function:\")\n\n[1] \"Using aggregate function:\"\n\nprint(cv_by_species)\n\n     Species Sepal.Length\n1     setosa   0.07041344\n2 versicolor   0.08695606\n3  virginica   0.09652089\n\n\nThe coefficient of variation measures relative variability. Lower values indicate less variability relative to the mean. Setosa has the lowest CV, indicating more consistent sepal lengths within that species.\n\n\n\nüîç Exercise 2b: Using the mtcars dataset, create a comprehensive analysis that includes:\n\nA summary of the data\nA correlation matrix of all numeric variables\nA linear model predicting mpg from weight and horsepower\nA visualization showing the relationship between weight and mpg with different colors for number of cylinders\n\n\n\n\n\n\n\nClick to see Exercise 2b Answer\n\n\n\n\n\n\n# Comprehensive mtcars analysis\n\n# 1. Summary of the data\nprint(\"=== MTCARS DATASET SUMMARY ===\")\n\n[1] \"=== MTCARS DATASET SUMMARY ===\"\n\nprint(summary(mtcars))\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\nprint(paste(\"Dataset dimensions:\", nrow(mtcars), \"rows,\", ncol(mtcars), \"columns\"))\n\n[1] \"Dataset dimensions: 32 rows, 11 columns\"\n\n# 2. Correlation matrix of all numeric variables\nprint(\"\\n=== CORRELATION MATRIX ===\")\n\n[1] \"\\n=== CORRELATION MATRIX ===\"\n\ncor_matrix &lt;- cor(mtcars)\nprint(round(cor_matrix, 2))\n\n       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\nmpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60  0.48 -0.55\ncyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 -0.49  0.53\ndisp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.71 -0.59 -0.56  0.39\nhp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.72 -0.24 -0.13  0.75\ndrat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.44  0.71  0.70 -0.09\nwt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.55 -0.69 -0.58  0.43\nqsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00  0.74 -0.23 -0.21 -0.66\nvs    0.66 -0.81 -0.71 -0.72  0.44 -0.55  0.74  1.00  0.17  0.21 -0.57\nam    0.60 -0.52 -0.59 -0.24  0.71 -0.69 -0.23  0.17  1.00  0.79  0.06\ngear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  0.21  0.79  1.00  0.27\ncarb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66 -0.57  0.06  0.27  1.00\n\n# 3. Linear model predicting mpg from weight and horsepower\nprint(\"\\n=== LINEAR REGRESSION MODEL ===\")\n\n[1] \"\\n=== LINEAR REGRESSION MODEL ===\"\n\nmpg_model &lt;- lm(mpg ~ wt + hp, data = mtcars)\nprint(summary(mpg_model))\n\n\nCall:\nlm(formula = mpg ~ wt + hp, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 37.22727    1.59879  23.285  &lt; 2e-16 ***\nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\n# Model interpretation\nr_squared &lt;- summary(mpg_model)$r.squared\nprint(paste(\"R-squared:\", round(r_squared, 3)))\n\n[1] \"R-squared: 0.827\"\n\nprint(paste(\"The model explains\", round(r_squared * 100, 1), \"% of the variance in MPG\"))\n\n[1] \"The model explains 82.7 % of the variance in MPG\"\n\n# 4. Visualization: Weight vs MPG colored by cylinders\nprint(\"\\n=== VISUALIZATION ===\")\n\n[1] \"\\n=== VISUALIZATION ===\"\n\n# Create color vector for cylinders\ncyl_colors &lt;- c(\"red\", \"blue\", \"green\")[as.factor(mtcars$cyl)]\n\nplot(mtcars$wt, mtcars$mpg,\n     main = \"MPG vs Weight by Number of Cylinders\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     col = cyl_colors,\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = paste(sort(unique(mtcars$cyl)), \"cylinders\"),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19,\n       title = \"Engine\")\n\n# Add regression line\nabline(lm(mpg ~ wt, data = mtcars), col = \"black\", lwd = 2, lty = 2)\n\n# Add text annotation\ntext(4.5, 30, paste(\"R¬≤ =\", round(summary(lm(mpg ~ wt, data = mtcars))$r.squared, 3)),\n     cex = 0.9, col = \"black\")\n\n\n\n\nKey Findings: - Correlation: Weight (wt) and horsepower (hp) are strongly negatively correlated with MPG - Model: The regression model explains about 83% of MPG variance using weight and horsepower - Visualization: Cars with fewer cylinders tend to be lighter and more fuel-efficient - Relationship: Clear negative relationship between weight and MPG across all cylinder groups"
  },
  {
    "objectID": "assignments/Lab One Part Two.html#part-2-data-analysis-visualization-and-programming-60-minutes",
    "href": "assignments/Lab One Part Two.html#part-2-data-analysis-visualization-and-programming-60-minutes",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "Let‚Äôs work with R‚Äôs built-in datasets and explore more advanced data manipulation techniques.\n\n\n\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\n\n\n\n\n\n\n\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    5.843333     3.057333     3.758000     1.199333 \n\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n   0.8280661    0.4358663    1.7652982    0.7622377 \n\n\n     Sepal.Length Sepal.Width Petal.Length Petal.Width\n[1,]          4.3         2.0          1.0         0.1\n[2,]          7.9         4.4          6.9         2.5\n\n\n\n\n\n\n\n\n\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\n    setosa versicolor  virginica \n 0.3333333  0.3333333  0.3333333 \n\n\n   \n     3  4  5\n  4  1  8  2\n  6  2  4  1\n  8 12  0  2\n\n\n   \n             3          4          5\n  4 0.09090909 0.72727273 0.18181818\n  6 0.28571429 0.57142857 0.14285714\n  8 0.85714286 0.00000000 0.14285714\n\n\n\n\n\n\n\n\n\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Large setosa flowers:\"\n\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n11          5.4         3.7          1.5         0.2  setosa\n15          5.8         4.0          1.2         0.2  setosa\n16          5.7         4.4          1.5         0.4  setosa\n17          5.4         3.9          1.3         0.4  setosa\n18          5.1         3.5          1.4         0.3  setosa\n19          5.7         3.8          1.7         0.3  setosa\n20          5.1         3.8          1.5         0.3  setosa\n21          5.4         3.4          1.7         0.2  setosa\n22          5.1         3.7          1.5         0.4  setosa\n24          5.1         3.3          1.7         0.5  setosa\n28          5.2         3.5          1.5         0.2  setosa\n29          5.2         3.4          1.4         0.2  setosa\n32          5.4         3.4          1.5         0.4  setosa\n33          5.2         4.1          1.5         0.1  setosa\n34          5.5         4.2          1.4         0.2  setosa\n37          5.5         3.5          1.3         0.2  setosa\n40          5.1         3.4          1.5         0.2  setosa\n45          5.1         3.8          1.9         0.4  setosa\n47          5.1         3.8          1.6         0.2  setosa\n49          5.3         3.7          1.5         0.2  setosa\n\n\n[1] \"Efficient and powerful cars:\"\n\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\n\n\n\n\n\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\n# Aggregating data\n# Average measurements by species\naggregate(. ~ Species, data = iris, FUN = mean)\n\n# Multiple statistics\naggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"Random sample of iris data:\"\n\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n109          6.7         2.5          5.8         1.8  virginica\n79           6.0         2.9          4.5         1.5 versicolor\n106          7.6         3.0          6.6         2.1  virginica\n9            4.4         2.9          1.4         0.2     setosa\n33           5.2         4.1          1.5         0.1     setosa\n31           4.8         3.1          1.6         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n114          5.7         2.5          5.0         2.0  virginica\n60           5.2         2.7          3.9         1.4 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n\n\n[1] \"Average measurements by species:\"\n\n\n     Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1     setosa        5.006       3.428        1.462       0.246\n2 versicolor        5.936       2.770        4.260       1.326\n3  virginica        6.588       2.974        5.552       2.026\n\n\n[1] \"MPG and HP statistics by cylinder:\"\n\n\n  cyl  mpg.mean    mpg.sd   hp.mean     hp.sd\n1   4 26.663636  4.509828  82.63636  20.93453\n2   6 19.742857  1.453567 122.28571  24.26049\n3   8 15.100000  2.560048 209.21429  50.97689\n\n\n\n\n\n\n\n\n\nR‚Äôs plotting capabilities are extensive. Let‚Äôs explore various types of plots.\n\n\n\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs perform various statistical tests and create models.\n\n\n\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n     mean    median        sd       min       max   q25.25%   q75.75% \n5.8433333 5.8000000 0.8280661 4.3000000 7.9000000 5.1000000 6.4000000 \n\n\n\n\n\n\n\n\n\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length         1.00       -0.12         0.87        0.82\nSepal.Width         -0.12        1.00        -0.43       -0.37\nPetal.Length         0.87       -0.43         1.00        0.96\nPetal.Width          0.82       -0.37         0.96        1.00\n\n\n\n    Pearson's product-moment correlation\n\ndata:  iris$Sepal.Length and iris$Sepal.Width\nt = -1.4403, df = 148, p-value = 0.1519\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.27269325  0.04351158\nsample estimates:\n       cor \n-0.1175698 \n\n\n\n\n\n\n\n\n\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  setosa_sepal and versicolor_sepal\nt = -10.521, df = 86.538, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.1057074 -0.7542926\nsample estimates:\nmean of x mean of y \n    5.006     5.936 \n\n\n\n\n\n\n\n\n\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0\n\n\n\n\n\n\n\n\n\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\n\n\n\n\n\n\n\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n\nCall:\nlm(formula = mpg ~ wt + hp + cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9290 -1.5598 -0.5311  1.1850  5.8986 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***\nwt          -3.16697    0.74058  -4.276 0.000199 ***\nhp          -0.01804    0.01188  -1.519 0.140015    \ncyl         -0.94162    0.55092  -1.709 0.098480 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.512 on 28 degrees of freedom\nMultiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 \nF-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11\n\n\nAnalysis of Variance Table\n\nModel 1: mpg ~ wt\nModel 2: mpg ~ wt + hp + cyl\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   \n1     30 278.32                                \n2     28 176.62  2     101.7 8.0615 0.001718 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[1] \"Predicted MPG: 20.9\"\n\n\n\n\n\n\n\n\n\nLearning to write functions and use control structures makes R much more powerful.\n\n\n\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"B\"\n\n\n[1] \"A\"\n\n\n\n\n\n\n\n\n\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] \"A\" \"B\" \"C\" \"D\" \"F\"\n\n\n\n\n\n\n\n\n\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n [1]  0  1  1  2  3  5  8 13 21 34\n\n\n\n\n\n\n\n\n\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n[1] 5 4 3 2 1\n\n\n\n\n\n\n\n\n\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)\n\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n\n\n$a\n[1] 3\n\n$b\n[1] 8\n\n$c\n[1] 13\n\n\n a  b  c \n 3  8 13 \n\n\n[1] 5 7 9\n\n\n\n\n\nüîç Exercise 2a: Create a function that calculates the coefficient of variation (CV = sd/mean) for a numeric vector. Test it on the Sepal.Length column of the iris dataset for each species.\n\n\n\n\n\n\nClick to see Exercise 2a Answer\n\n\n\n\n\n\n# Create coefficient of variation function\ncoeff_variation &lt;- function(x) {\n  cv &lt;- sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\n  return(cv)\n}\n\n# Test on Sepal.Length for each species\nspecies_list &lt;- levels(iris$Species)\ncv_results &lt;- sapply(species_list, function(species) {\n  species_data &lt;- iris[iris$Species == species, \"Sepal.Length\"]\n  coeff_variation(species_data)\n})\n\nprint(\"Coefficient of Variation for Sepal.Length by Species:\")\n\n[1] \"Coefficient of Variation for Sepal.Length by Species:\"\n\nprint(round(cv_results, 4))\n\n    setosa versicolor  virginica \n    0.0704     0.0870     0.0965 \n\n# Alternative approach using aggregate\ncv_by_species &lt;- aggregate(Sepal.Length ~ Species, data = iris, \n                          FUN = function(x) sd(x)/mean(x))\nprint(\"Using aggregate function:\")\n\n[1] \"Using aggregate function:\"\n\nprint(cv_by_species)\n\n     Species Sepal.Length\n1     setosa   0.07041344\n2 versicolor   0.08695606\n3  virginica   0.09652089\n\n\nThe coefficient of variation measures relative variability. Lower values indicate less variability relative to the mean. Setosa has the lowest CV, indicating more consistent sepal lengths within that species.\n\n\n\nüîç Exercise 2b: Using the mtcars dataset, create a comprehensive analysis that includes:\n\nA summary of the data\nA correlation matrix of all numeric variables\nA linear model predicting mpg from weight and horsepower\nA visualization showing the relationship between weight and mpg with different colors for number of cylinders\n\n\n\n\n\n\n\nClick to see Exercise 2b Answer\n\n\n\n\n\n\n# Comprehensive mtcars analysis\n\n# 1. Summary of the data\nprint(\"=== MTCARS DATASET SUMMARY ===\")\n\n[1] \"=== MTCARS DATASET SUMMARY ===\"\n\nprint(summary(mtcars))\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\nprint(paste(\"Dataset dimensions:\", nrow(mtcars), \"rows,\", ncol(mtcars), \"columns\"))\n\n[1] \"Dataset dimensions: 32 rows, 11 columns\"\n\n# 2. Correlation matrix of all numeric variables\nprint(\"\\n=== CORRELATION MATRIX ===\")\n\n[1] \"\\n=== CORRELATION MATRIX ===\"\n\ncor_matrix &lt;- cor(mtcars)\nprint(round(cor_matrix, 2))\n\n       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\nmpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.66  0.60  0.48 -0.55\ncyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.81 -0.52 -0.49  0.53\ndisp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.71 -0.59 -0.56  0.39\nhp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.72 -0.24 -0.13  0.75\ndrat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.44  0.71  0.70 -0.09\nwt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.55 -0.69 -0.58  0.43\nqsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00  0.74 -0.23 -0.21 -0.66\nvs    0.66 -0.81 -0.71 -0.72  0.44 -0.55  0.74  1.00  0.17  0.21 -0.57\nam    0.60 -0.52 -0.59 -0.24  0.71 -0.69 -0.23  0.17  1.00  0.79  0.06\ngear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  0.21  0.79  1.00  0.27\ncarb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66 -0.57  0.06  0.27  1.00\n\n# 3. Linear model predicting mpg from weight and horsepower\nprint(\"\\n=== LINEAR REGRESSION MODEL ===\")\n\n[1] \"\\n=== LINEAR REGRESSION MODEL ===\"\n\nmpg_model &lt;- lm(mpg ~ wt + hp, data = mtcars)\nprint(summary(mpg_model))\n\n\nCall:\nlm(formula = mpg ~ wt + hp, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 37.22727    1.59879  23.285  &lt; 2e-16 ***\nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,    Adjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n\n# Model interpretation\nr_squared &lt;- summary(mpg_model)$r.squared\nprint(paste(\"R-squared:\", round(r_squared, 3)))\n\n[1] \"R-squared: 0.827\"\n\nprint(paste(\"The model explains\", round(r_squared * 100, 1), \"% of the variance in MPG\"))\n\n[1] \"The model explains 82.7 % of the variance in MPG\"\n\n# 4. Visualization: Weight vs MPG colored by cylinders\nprint(\"\\n=== VISUALIZATION ===\")\n\n[1] \"\\n=== VISUALIZATION ===\"\n\n# Create color vector for cylinders\ncyl_colors &lt;- c(\"red\", \"blue\", \"green\")[as.factor(mtcars$cyl)]\n\nplot(mtcars$wt, mtcars$mpg,\n     main = \"MPG vs Weight by Number of Cylinders\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     col = cyl_colors,\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = paste(sort(unique(mtcars$cyl)), \"cylinders\"),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19,\n       title = \"Engine\")\n\n# Add regression line\nabline(lm(mpg ~ wt, data = mtcars), col = \"black\", lwd = 2, lty = 2)\n\n# Add text annotation\ntext(4.5, 30, paste(\"R¬≤ =\", round(summary(lm(mpg ~ wt, data = mtcars))$r.squared, 3)),\n     cex = 0.9, col = \"black\")\n\n\n\n\nKey Findings: - Correlation: Weight (wt) and horsepower (hp) are strongly negatively correlated with MPG - Model: The regression model explains about 83% of MPG variance using weight and horsepower - Visualization: Cars with fewer cylinders tend to be lighter and more fuel-efficient - Relationship: Clear negative relationship between weight and MPG across all cylinder groups"
  },
  {
    "objectID": "assignments/Lab Two.html",
    "href": "assignments/Lab Two.html",
    "title": "CSS Lab Two",
    "section": "",
    "text": "By the end of this lab, you will be able to:\n\nUnderstand what file paths are and how to find them\nLoad CSV and XML data files into R\nExplore basic data structure and quality\nUnderstand different types of data sources\nPractice basic data exploration techniques"
  },
  {
    "objectID": "assignments/Lab Two.html#learning-objectives",
    "href": "assignments/Lab Two.html#learning-objectives",
    "title": "CSS Lab Two",
    "section": "",
    "text": "By the end of this lab, you will be able to:\n\nUnderstand what file paths are and how to find them\nLoad CSV and XML data files into R\nExplore basic data structure and quality\nUnderstand different types of data sources\nPractice basic data exploration techniques"
  },
  {
    "objectID": "assignments/Lab Two.html#assignment-and-data-access",
    "href": "assignments/Lab Two.html#assignment-and-data-access",
    "title": "CSS Lab Two",
    "section": "Assignment and Data Access",
    "text": "Assignment and Data Access\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n&lt;-\nAssignment operator\nSaves data to a variable\nmy_data &lt;- read_csv(\"file.csv\")\n\n\n=\nAlternative assignment\nSame as &lt;- (less common)\nmy_data = read_csv(\"file.csv\")\n\n\n$\nDollar sign\nSelects a column from a dataset\nmy_data$age\n\n\n[[]]\nDouble brackets\nAlternative way to select columns\nmy_data[[\"age\"]]\n\n\n[]\nSquare brackets\nSelects rows/columns by position\nmy_data[1:5, 2:4]"
  },
  {
    "objectID": "assignments/Lab Two.html#pipes-and-connections",
    "href": "assignments/Lab Two.html#pipes-and-connections",
    "title": "CSS Lab Two",
    "section": "Pipes and Connections",
    "text": "Pipes and Connections\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n%&gt;%\nPipe operator\nPasses result to the next function\ndata %&gt;% filter(age &gt; 18)\n\n\n\\|&gt;\nNative pipe\nNew R pipe (same as %&gt;%)\ndata \\|&gt; filter(age &gt; 18)"
  },
  {
    "objectID": "assignments/Lab Two.html#comparison-operators",
    "href": "assignments/Lab Two.html#comparison-operators",
    "title": "CSS Lab Two",
    "section": "Comparison Operators",
    "text": "Comparison Operators\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n==\nEqual to\nChecks if values are exactly equal\nage == 25\n\n\n!=\nNot equal to\nChecks if values are different\nage != 25\n\n\n&gt;\nGreater than\nChecks if left is bigger\nage &gt; 18\n\n\n&lt;\nLess than\nChecks if left is smaller\nage &lt; 65\n\n\n&gt;=\nGreater than or equal\nChecks if left is bigger or same\nage &gt;= 18\n\n\n&lt;=\nLess than or equal\nChecks if left is smaller or same\nage &lt;= 65"
  },
  {
    "objectID": "assignments/Lab Two.html#logical-operators",
    "href": "assignments/Lab Two.html#logical-operators",
    "title": "CSS Lab Two",
    "section": "Logical Operators",
    "text": "Logical Operators\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n&\nAND\nBoth conditions must be true\nage &gt; 18 & age &lt; 65\n\n\n\\|\nOR\nEither condition can be true\nstate == \"CA\" \\| state == \"NY\"\n\n\n!\nNOT\nReverses TRUE/FALSE\n!is.na(age)"
  },
  {
    "objectID": "assignments/Lab Two.html#mathematical-operators",
    "href": "assignments/Lab Two.html#mathematical-operators",
    "title": "CSS Lab Two",
    "section": "Mathematical Operators",
    "text": "Mathematical Operators\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n+\nAddition\nAdds numbers\nage + 1\n\n\n-\nSubtraction\nSubtracts numbers\nage - 1\n\n\n*\nMultiplication\nMultiplies numbers\nage * 2\n\n\n/\nDivision\nDivides numbers\nage / 2\n\n\n^\nExponent\nRaises to a power\nage^2"
  },
  {
    "objectID": "assignments/Lab Two.html#special-characters",
    "href": "assignments/Lab Two.html#special-characters",
    "title": "CSS Lab Two",
    "section": "Special Characters",
    "text": "Special Characters\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n~\nTilde (formula)\nCreates formulas for functions\nsummarise(across(everything(), ~mean(.)))\n\n\n.\nDot\nRepresents ‚Äúthe current data‚Äù in pipes\ndata %&gt;% filter(age &gt; mean(.$age))\n\n\n#\nHash/Comment\nCreates comments (ignored by R)\n# This is a comment\n\n\n\"\"\nQuotes\nDefines text strings\n\"Hello World\"\n\n\n''\nSingle quotes\nAlternative for text strings\n'Hello World'"
  },
  {
    "objectID": "assignments/Lab Two.html#missing-data-and-special-values",
    "href": "assignments/Lab Two.html#missing-data-and-special-values",
    "title": "CSS Lab Two",
    "section": "Missing Data and Special Values",
    "text": "Missing Data and Special Values\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\nNA\nNot Available\nRepresents missing data\nc(1, 2, NA, 4)\n\n\nNULL\nNull\nRepresents ‚Äúnothing‚Äù or empty\nmy_var &lt;- NULL\n\n\nInf\nInfinity\nResult of dividing by zero\n1/0\n\n\nNaN\nNot a Number\nResult of impossible math\n0/0"
  },
  {
    "objectID": "assignments/Lab Two.html#function-and-data-creation",
    "href": "assignments/Lab Two.html#function-and-data-creation",
    "title": "CSS Lab Two",
    "section": "Function and Data Creation",
    "text": "Function and Data Creation\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n()\nParentheses\nGroups expressions or function arguments\nmean(c(1,2,3))\n\n\nc()\nCombine function\nCreates vectors (lists of values)\nc(1, 2, 3, 4)\n\n\n{}\nCurly braces\nGroups multiple lines of code\nif (x &gt; 0) { print(\"positive\") }"
  },
  {
    "objectID": "assignments/Lab Two.html#text-and-output",
    "href": "assignments/Lab Two.html#text-and-output",
    "title": "CSS Lab Two",
    "section": "Text and Output",
    "text": "Text and Output\n\n\n\n\n\n\n\n\n\nSymbol\nName\nWhat it does\nExample\n\n\n\n\n\\n\nNew line\nCreates line break in text output\ncat(\"Line 1\\nLine 2\")\n\n\n\\t\nTab\nCreates tab spacing\ncat(\"Name\\tAge\")\n\n\npaste()\nPaste function\nCombines text\npaste(\"Hello\", \"World\")\n\n\npaste0()\nPaste with no space\nCombines text without spaces\npaste0(\"Hello\", \"World\")"
  },
  {
    "objectID": "assignments/Lab Two.html#common-function-patterns",
    "href": "assignments/Lab Two.html#common-function-patterns",
    "title": "CSS Lab Two",
    "section": "Common Function Patterns",
    "text": "Common Function Patterns\n\nData Exploration\ndata %&gt;%                    # Take the data, then\n  filter(age &gt; 18) %&gt;%      # Keep rows where age &gt; 18, then  \n  select(name, age) %&gt;%     # Pick only name and age columns, then\n  arrange(desc(age))        # Sort by age (highest first)\n\n\nSummary Statistics\ndata %&gt;%                              # Take the data, then\n  group_by(category) %&gt;%              # Group by category, then\n  summarise(                          # Create summaries:\n    count = n(),                      # Count rows in each group\n    avg_age = mean(age, na.rm = TRUE) # Average age (remove missing)\n  )\n\n\nMissing Value Checks\nsum(is.na(data$age))        # Count missing values in age column\ndata %&gt;%                    # Take the data, then\n  filter(!is.na(age))       # Keep rows where age is NOT missing"
  },
  {
    "objectID": "assignments/Lab Two.html#pro-tips-for-beginners",
    "href": "assignments/Lab Two.html#pro-tips-for-beginners",
    "title": "CSS Lab Two",
    "section": "Pro Tips for Beginners",
    "text": "Pro Tips for Beginners\n\nSpacing doesn‚Äôt matter: x&lt;-5 and x &lt;- 5 both work, but x &lt;- 5 is easier to read\nCase matters: Data and data are different things\nUse tab completion: Type the first few letters and press Tab for suggestions\nRead error messages: They often tell you exactly what‚Äôs wrong\nUse the help: Type ?function_name to get help (like ?mean)"
  },
  {
    "objectID": "assignments/Lab Two.html#when-you-see-this-it-means",
    "href": "assignments/Lab Two.html#when-you-see-this-it-means",
    "title": "CSS Lab Two",
    "section": "When You See This‚Ä¶ It Means‚Ä¶",
    "text": "When You See This‚Ä¶ It Means‚Ä¶\n\nError: object 'x' not found ‚Üí You haven‚Äôt created the variable x yet\nError: could not find function \"glimpse\" ‚Üí You need to load a package first (library(tidyverse))\nWarning: NAs introduced by coercion ‚Üí R couldn‚Äôt convert some values (like text to numbers)\n[1] 5 10 15 ‚Üí The output shows position numbers [1] and the values 5 10 15"
  },
  {
    "objectID": "assignments/Lab Two.html#part-1-understanding-file-paths-and-loading-data-20-minutes",
    "href": "assignments/Lab Two.html#part-1-understanding-file-paths-and-loading-data-20-minutes",
    "title": "CSS Lab Two",
    "section": "Part 1: Understanding File Paths and Loading Data (20 minutes)",
    "text": "Part 1: Understanding File Paths and Loading Data (20 minutes)\n\nDownload Data from D2L\n\nFor this lab, you need to download two datasets from D2L from the Data folder (Lab 2 Data)\n\n\n\nWhat is a File Path?\nA file path tells your computer exactly where to find a file. Think of it like a street address for your files.\nExample file path: /Users/mariarepetto/Documents/CSS Course Fall 2025/usa_00042.xml\nThis breaks down as: - /Users/mariarepetto/ = Your user folder - Documents/ = Documents folder - CSS Course Fall 2025/ = Your class folder - usa_00042.xml = The actual file name\n\n\nHow to Find Your File Path\nOn Mac: 1. Right-click on your file 2. Hold down the Option key 3. Select ‚ÄúCopy as Pathname‚Äù\nOn Windows: 1. Right-click on your file 2. Select ‚ÄúProperties‚Äù 3. Copy the path shown\nThe Easy Way in RStudio: 1. In the Files panel (bottom right), navigate to your file 2. Click on the file name 3. RStudio will show you the path\n\n\nLoading Your Data\nWe have two datasets to work with: 1. A Reddit dataset (CSV file) 2. A Census dataset (XML + CSV files)\n\n# Load required libraries\nlibrary(tidyverse)  # loads a collection of packages for data manipulation and visualization\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.5.2     ‚úî purrr   0.3.5\n‚úî tibble  3.1.8     ‚úî dplyr   1.1.0\n‚úî tidyr   1.2.1     ‚úî stringr 1.5.0\n‚úî readr   2.1.3     ‚úî forcats 0.5.2\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(ipumsr)     # loads a specialized package for working with IPUMS census data\n\n# Load the Reddit dataset (CSV file)\n# Replace this path with YOUR actual file path\nreddit_data &lt;- read_csv(\"/Users/mariarepetto/Documents/CSS Course Fall 2025/NetflixBestOf_reddit.csv\")\n\nRows: 467 Columns: 9\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (7): title, score, id, subreddit, url, body, timestamp\ndbl (2): num_comments, created\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# read_csv() = function that reads comma-separated value files into R\n# &lt;- = assignment operator that saves the data into a variable called \"reddit_data\"\n\n# Load the Census dataset (XML + data file)\n# The XML file contains information about the data structure\nddi &lt;- read_ipums_ddi(\"/Users/mariarepetto/Documents/CSS Course Fall 2025/usa_00042.xml\")\n# read_ipums_ddi() = reads the data definition file that explains the census data structure\n# ddi = \"data definition interface\" - contains metadata about variables\n\ncensus_data &lt;- read_ipums_micro(ddi)\n\nUse of data from IPUMS USA is subject to conditions including that users should\ncite the data appropriately. Use command `ipums_conditions()` for more details.\n\n# read_ipums_micro() = uses the ddi information to properly load the census data\n# \"micro\" refers to individual-level data (each row = one person)\n\n# Let's see what we loaded\ncat(\"Reddit data dimensions:\", nrow(reddit_data), \"rows x\", ncol(reddit_data), \"columns\\n\")\n\nReddit data dimensions: 467 rows x 9 columns\n\n# cat() = prints text to the console (like print, but for simple text)\n# nrow() = counts the number of rows in the dataset\n# ncol() = counts the number of columns in the dataset\n# \\n = creates a new line\n\ncat(\"Census data dimensions:\", nrow(census_data), \"rows x\", ncol(census_data), \"columns\\n\")\n\nCensus data dimensions: 3405809 rows x 23 columns\n\n\nImportant: You need to change the file paths above to match where YOUR files are located on your computer!"
  },
  {
    "objectID": "assignments/Lab Two.html#part-2-exploring-the-reddit-dataset-15-minutes",
    "href": "assignments/Lab Two.html#part-2-exploring-the-reddit-dataset-15-minutes",
    "title": "CSS Lab Two",
    "section": "Part 2: Exploring the Reddit Dataset (15 minutes)",
    "text": "Part 2: Exploring the Reddit Dataset (15 minutes)\n\nBasic Data Exploration\n\n# Look at the structure of our Reddit data\nglimpse(reddit_data)\n\nRows: 467\nColumns: 9\n$ title        &lt;chr&gt; \"[Discussion] Am I just late to some change, or does Netf‚Ä¶\n$ score        &lt;chr&gt; \"830\", \"36\", \"12\", \"514\", \"110\", \"0\", \"471\", \"1\", \"100\", ‚Ä¶\n$ id           &lt;chr&gt; \"qtq00z\", \"qu96s0\", \"qu3xtc\", \"qtc3c4\", \"qtipzk\", \"quei6n‚Ä¶\n$ subreddit    &lt;chr&gt; \"NetflixBestOf\", \"NetflixBestOf\", \"NetflixBestOf\", \"Netfl‚Ä¶\n$ url          &lt;chr&gt; \"https://www.reddit.com/r/NetflixBestOf/comments/qtq00z/d‚Ä¶\n$ num_comments &lt;dbl&gt; 77, 7, 2, 86, 40, 1, 65, 0, 137, 44, 14, 15, 89, 61, 19, ‚Ä¶\n$ body         &lt;chr&gt; \"A lot of these are older, but I'm seeing more good older‚Ä¶\n$ created      &lt;dbl&gt; 1636897097, 1636954647, 1636937195, 1636843724, 163686686‚Ä¶\n$ timestamp    &lt;chr&gt; \"11/14/21 14:38\", \"11/15/21 6:37\", \"11/15/21 1:46\", \"11/1‚Ä¶\n\n# glimpse() = shows a compact view of your data including:\n# - number of rows and columns\n# - column names and data types\n# - first few values in each column\n\n# See the first few rows\nhead(reddit_data)\n\n# A tibble: 6 √ó 9\n  title                  score id    subre‚Ä¶¬π url   num_c‚Ä¶¬≤ body  created times‚Ä¶¬≥\n  &lt;chr&gt;                  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  \n1 [Discussion] Am I jus‚Ä¶ 830   qtq0‚Ä¶ Netfli‚Ä¶ http‚Ä¶      77 \"A l‚Ä¶  1.64e9 11/14/‚Ä¶\n2 [REQUEST] Shows simil‚Ä¶ 36    qu96‚Ä¶ Netfli‚Ä¶ http‚Ä¶       7 \"Lov‚Ä¶  1.64e9 11/15/‚Ä¶\n3 [DISCUSSION] (US) The‚Ä¶ 12    qu3x‚Ä¶ Netfli‚Ä¶ http‚Ä¶       2 \"Rem‚Ä¶  1.64e9 11/15/‚Ä¶\n4 [US] Love Harder (202‚Ä¶ 514   qtc3‚Ä¶ Netfli‚Ä¶ http‚Ä¶      86  &lt;NA&gt;  1.64e9 11/13/‚Ä¶\n5 [DISCUSSION] Arcane (‚Ä¶ 110   qtip‚Ä¶ Netfli‚Ä¶ http‚Ä¶      40 \"Hol‚Ä¶  1.64e9 11/14/‚Ä¶\n6 Top 10 Best NETFLIX S‚Ä¶ 0     quei‚Ä¶ Netfli‚Ä¶ http‚Ä¶       1  &lt;NA&gt;  1.64e9 11/15/‚Ä¶\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãsubreddit, ¬≤‚Äãnum_comments, ¬≥‚Äãtimestamp\n\n# head() = shows the first 6 rows of your dataset (like peeking at the top)\n\n# Check what columns we have\nnames(reddit_data)\n\n[1] \"title\"        \"score\"        \"id\"           \"subreddit\"    \"url\"         \n[6] \"num_comments\" \"body\"         \"created\"      \"timestamp\"   \n\n# names() = returns a list of all column names in your dataset\n\n\n\nUnderstanding Reddit Data\nReddit posts have several key pieces of information: - Title: The headline of the post - Score: How many upvotes minus downvotes - Comments: Number of comments on the post - Subreddit: Which community it was posted in\n\n# Basic summary statistics\nsummary(reddit_data)\n\n    title              score                id             subreddit        \n Length:467         Length:467         Length:467         Length:467        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     url             num_comments         body              created         \n Length:467         Min.   :   0.00   Length:467         Min.   :1.632e+09  \n Class :character   1st Qu.:   8.00   Class :character   1st Qu.:1.633e+09  \n Mode  :character   Median :  17.50   Mode  :character   Median :1.634e+09  \n                    Mean   :  56.92                      Mean   :1.634e+09  \n                    3rd Qu.:  52.75                      3rd Qu.:1.636e+09  \n                    Max.   :1082.00                      Max.   :1.637e+09  \n                    NA's   :5                            NA's   :6          \n  timestamp        \n Length:467        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n# summary() = provides basic statistics for each column:\n# - for numbers: min, max, mean, median, quartiles\n# - for text: length and class information\n\n# Look at the most popular posts (highest scores)\nreddit_data %&gt;%\n  arrange(desc(score)) %&gt;%\n  select(title, score, num_comments) %&gt;%\n  head(10)\n\n# A tibble: 10 √ó 3\n   title                                                           score num_c‚Ä¶¬π\n   &lt;chr&gt;                                                           &lt;chr&gt;   &lt;dbl&gt;\n 1 Because when someone's creation can be taken away that easily ‚Ä¶ love       NA\n 2 [Request] The 'next game of thrones' shows                      98        114\n 3 [REQUEST] Shows with a badass female lead like My Name          91         71\n 4 [US] House of Secrets: The Burari Deaths (2021): This docuseri‚Ä¶ 90         23\n 5 [REQUEST] movies that will make you cry your eyes out           9          96\n 6 [REQUEST] Seemingly post-apocalyptic movies or shows where bot‚Ä¶ 9          19\n 7 [Request] Adult Animation that isn‚Äôt aimed at 14 year olds wit‚Ä¶ 9          30\n 8 [discussion] Sex Education, am I the only or. Watching it on N‚Ä¶ 9          10\n 9 [REQUEST] Looking for shows like Alice in Borderland and Squid‚Ä¶ 9           7\n10 [Request] suggest me some series like outlander                 9          17\n# ‚Ä¶ with abbreviated variable name ¬π‚Äãnum_comments\n\n# Breaking this down line by line:\n# reddit_data = our dataset\n# %&gt;% = pipe operator - passes the result to the next function\n# arrange(desc(score)) = sorts rows by score column in descending order (highest first)\n# desc() = descending order function\n# select(title, score, num_comments) = picks only these 3 columns to show\n# head(10) = shows only the first 10 rows\n\n# Check for missing data\nreddit_data %&gt;%\n  summarise(across(everything(), ~sum(is.na(.))))\n\n# A tibble: 1 √ó 9\n  title score    id subreddit   url num_comments  body created timestamp\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;int&gt;        &lt;int&gt; &lt;int&gt;   &lt;int&gt;     &lt;int&gt;\n1     2     3     3         5     5            5   113       6         6\n\n# Breaking this down:\n# summarise() = creates summary statistics\n# across() = applies a function to multiple columns\n# everything() = refers to all columns in the dataset\n# ~ = creates a formula (like saying \"for each column, do this:\")\n# sum(is.na(.)) = counts missing values (NA = \"Not Available\")\n# is.na() = checks if each value is missing (returns TRUE/FALSE)\n# sum() = adds up all the TRUE values (TRUE = 1, FALSE = 0)\n# . = refers to each column as the function goes through them\n\n\n\nData Quality Checks\n\n# How many unique posts do we have?\nnrow(reddit_data)\n\n[1] 467\n\n# nrow() = counts total number of rows (each row = one post)\n\n# What's the range of scores?\nrange(reddit_data$score, na.rm = TRUE)\n\n[1] \"0\"    \"love\"\n\n# range() = finds the minimum and maximum values\n# reddit_data$score = selects just the \"score\" column from reddit_data\n# $ = dollar sign operator to access a specific column\n# na.rm = TRUE = removes missing values before calculating (na.rm = \"NA remove\")\n\n# What's the range of comment counts?\nrange(reddit_data$num_comments, na.rm = TRUE)\n\n[1]    0 1082\n\n# Are there any deleted posts?\nsum(reddit_data$title == \"[deleted]\", na.rm = TRUE)\n\n[1] 0\n\n# == = equality operator (checks if values are exactly equal)\n# This creates TRUE/FALSE for each row, then sum() counts the TRUEs\n\nsum(reddit_data$author == \"[deleted]\", na.rm = TRUE)\n\nWarning: Unknown or uninitialised column: `author`.\n\n\n[1] 0"
  },
  {
    "objectID": "assignments/Lab Two.html#part-3-exploring-the-census-dataset-20-minutes",
    "href": "assignments/Lab Two.html#part-3-exploring-the-census-dataset-20-minutes",
    "title": "CSS Lab Two",
    "section": "Part 3: Exploring the Census Dataset (20 minutes)",
    "text": "Part 3: Exploring the Census Dataset (20 minutes)\n\nUnderstanding Census Data\nCensus data is very different from Reddit data: - Each row represents one person - Variables are coded with numbers - There are ‚Äúweights‚Äù that tell us how many people each row represents\n\n# Look at the structure\nglimpse(census_data)\n\nRows: 3,405,809\nColumns: 23\n$ YEAR     &lt;int&gt; 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2‚Ä¶\n$ SAMPLE   &lt;int+lbl&gt; 202301, 202301, 202301, 202301, 202301, 202301, 202301, 2‚Ä¶\n$ SERIAL   &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18‚Ä¶\n$ CBSERIAL &lt;dbl&gt; 2.02301e+12, 2.02301e+12, 2.02301e+12, 2.02301e+12, 2.02301e+‚Ä¶\n$ HHWT     &lt;dbl&gt; 6, 27, 47, 11, 57, 52, 43, 1, 3, 41, 43, 39, 36, 65, 47, 45, ‚Ä¶\n$ CLUSTER  &lt;dbl&gt; 2.023e+12, 2.023e+12, 2.023e+12, 2.023e+12, 2.023e+12, 2.023e‚Ä¶\n$ STRATA   &lt;dbl&gt; 280201, 10001, 40201, 270201, 280201, 120201, 180101, 140201,‚Ä¶\n$ GQ       &lt;int+lbl&gt; 3, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 3, 3, ‚Ä¶\n$ PERNUM   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ PERWT    &lt;dbl&gt; 6, 27, 47, 11, 57, 52, 43, 1, 3, 41, 43, 39, 36, 65, 47, 45, ‚Ä¶\n$ SEX      &lt;int+lbl&gt; 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, ‚Ä¶\n$ AGE      &lt;int+lbl&gt; 86, 60, 20, 13, 18, 19, 37, 71, 75, 19, 37, 18, 59, 72, 3‚Ä¶\n$ RACE     &lt;int+lbl&gt; 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, ‚Ä¶\n$ RACED    &lt;int+lbl&gt; 200, 100, 100, 200, 100, 100, 200, 100, 100, 100, 200, 10‚Ä¶\n$ HISPAN   &lt;int+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, ‚Ä¶\n$ HISPAND  &lt;int+lbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 498, 0‚Ä¶\n$ BPL      &lt;int+lbl&gt; 1, 25, 1, 28, 17, 1, 1, 1, 1, 1, 1, 5, 1, 1, 13, 1, 12, 2‚Ä¶\n$ BPLD     &lt;int+lbl&gt; 100, 2500, 100, 2800, 1700, 100, 100, 100, 100, 100, 100,‚Ä¶\n$ EDUC     &lt;int+lbl&gt; 6, 6, 7, 2, 6, 7, 5, 10, 10, 7, 2, 6, 7, 10, 7, 6, 6, 6, ‚Ä¶\n$ EDUCD    &lt;int+lbl&gt; 63, 63, 71, 26, 65, 71, 50, 101, 101, 71, 25, 63, 71, 101‚Ä¶\n$ EMPSTAT  &lt;int+lbl&gt; 3, 3, 3, 0, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶\n$ EMPSTATD &lt;int+lbl&gt; 30, 30, 30, 0, 30, 30, 30, 30, 30, 10, 30, 20, 30, 30, 30‚Ä¶\n$ INCTOT   &lt;dbl+lbl&gt;   11500,       0,       0, 9999999,    2500,     500,    ‚Ä¶\n\n# glimpse() = same as before, shows structure of the census data\n\n# Basic exploration\nhead(census_data)\n\n# A tibble: 6 √ó 23\n   YEAR SAMPLE          SERIAL CBSER‚Ä¶¬π  HHWT CLUSTER STRATA GQ      PERNUM PERWT\n  &lt;int&gt; &lt;int+lbl&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;int+l&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1  2023 202301 [2023 A‚Ä¶      1 2.02e12     6 2.02e12 280201 3 [Gro‚Ä¶      1     6\n2  2023 202301 [2023 A‚Ä¶      2 2.02e12    27 2.02e12  10001 3 [Gro‚Ä¶      1    27\n3  2023 202301 [2023 A‚Ä¶      3 2.02e12    47 2.02e12  40201 4 [Oth‚Ä¶      1    47\n4  2023 202301 [2023 A‚Ä¶      4 2.02e12    11 2.02e12 270201 3 [Gro‚Ä¶      1    11\n5  2023 202301 [2023 A‚Ä¶      5 2.02e12    57 2.02e12 280201 4 [Oth‚Ä¶      1    57\n6  2023 202301 [2023 A‚Ä¶      6 2.02e12    52 2.02e12 120201 4 [Oth‚Ä¶      1    52\n# ‚Ä¶ with 13 more variables: SEX &lt;int+lbl&gt;, AGE &lt;int+lbl&gt;, RACE &lt;int+lbl&gt;,\n#   RACED &lt;int+lbl&gt;, HISPAN &lt;int+lbl&gt;, HISPAND &lt;int+lbl&gt;, BPL &lt;int+lbl&gt;,\n#   BPLD &lt;int+lbl&gt;, EDUC &lt;int+lbl&gt;, EDUCD &lt;int+lbl&gt;, EMPSTAT &lt;int+lbl&gt;,\n#   EMPSTATD &lt;int+lbl&gt;, INCTOT &lt;dbl+lbl&gt;, and abbreviated variable name\n#   ¬π‚ÄãCBSERIAL\n\n# head() = shows first 6 rows of census data\n\n\n\nUnderstanding the Variables\n\n# Look at the different variables we have\nnames(census_data)\n\n [1] \"YEAR\"     \"SAMPLE\"   \"SERIAL\"   \"CBSERIAL\" \"HHWT\"     \"CLUSTER\" \n [7] \"STRATA\"   \"GQ\"       \"PERNUM\"   \"PERWT\"    \"SEX\"      \"AGE\"     \n[13] \"RACE\"     \"RACED\"    \"HISPAN\"   \"HISPAND\"  \"BPL\"      \"BPLD\"    \n[19] \"EDUC\"     \"EDUCD\"    \"EMPSTAT\"  \"EMPSTATD\" \"INCTOT\"  \n\n# names() = lists all column names in the census dataset\n\n# Check the age distribution\ntable(census_data$AGE)\n\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n29468 30628 30282 31637 32142 33169 34012 35303 35796 36209 36498 36748 37539 \n   13    14    15    16    17    18    19    20    21    22    23    24    25 \n38443 39503 40787 41058 41063 47796 47352 41432 38999 37666 37188 36424 37164 \n   26    27    28    29    30    31    32    33    34    35    36    37    38 \n37443 38011 39090 39473 41231 41441 42557 43081 42478 42408 41787 41257 41819 \n   39    40    41    42    43    44    45    46    47    48    49    50    51 \n40742 42355 41134 41392 40633 39104 39090 38454 37738 37962 37764 39864 40408 \n   52    53    54    55    56    57    58    59    60    61    62    63    64 \n43596 43554 42408 42433 42203 43698 46674 47945 50144 49602 51043 50732 50528 \n   65    66    67    68    69    70    71    72    73    74    75    76    77 \n51074 50283 48919 47848 46471 45497 43072 41546 39418 38131 37777 37201 28189 \n   78    79    80    81    82    83    84    85    86    87    88    89    90 \n26078 25533 24892 20958 18528 16503 14910 13719 11697 10355  9224  6826  4790 \n   91    92    93    94    95    96 \n 1478  4566  5704 12299  4637   104 \n\n# table() = counts how many people are at each age\n# Creates a frequency table showing: Age | Count\n\n# Look at sex distribution (1 = Male, 2 = Female)\ntable(census_data$SEX)\n\n\n      1       2 \n1671915 1733894 \n\n# table() = counts how many people are coded as 1 vs 2\n\n# Look at race categories\ntable(census_data$RACE)\n\n\n      1       2       3       4       5       6       7       8       9 \n2273916  295055   43601   51180    8479  153429  196480  355732   27937 \n\n# table() = shows distribution across different race codes\n\n# Education levels\ntable(census_data$EDUC)\n\n\n      0       1       2       3       4       5       6       7       8      10 \n 197184  233284  200731   65217   70129   80043 1018817  364890  235111  568171 \n     11 \n 372232 \n\n# table() = shows distribution across education level codes\n\n\n\nUnderstanding Survey Weights\nSurvey weights are crucial in census data. They tell us how many people in the population each person in our sample represents.\n\n# Look at the weights\nsummary(census_data$PERWT)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00   47.00   72.00   98.34  117.00 2225.00 \n\n# summary() = shows min, max, mean, median, etc. for the weight variable\n# PERWT = person weight (how many people each row represents)\n\n# Total sample size\nnrow(census_data)\n\n[1] 3405809\n\n# nrow() = counts how many individual people are in our sample\n\n# Total population represented\nsum(census_data$PERWT)\n\n[1] 334914896\n\n# sum() = adds up all the weights to get total population represented\n\n# Average weight per person\nmean(census_data$PERWT)\n\n[1] 98.33637\n\n# mean() = calculates the average weight value\n\n\n\nBasic Analysis\n\n# Calculate weighted percentages\n# What percentage of the population is male vs female?\n\n# Count by sex, weighted\nsex_counts &lt;- census_data %&gt;%\n  group_by(SEX) %&gt;%\n  summarise(\n    sample_count = n(),\n    weighted_count = sum(PERWT),\n    percentage = weighted_count / sum(census_data$PERWT) * 100\n  )\n\n# Breaking this down:\n# group_by(SEX) = groups the data by sex categories (1 and 2)\n# summarise() = creates summary statistics for each group\n# n() = counts the number of rows in each group (sample size)\n# sum(PERWT) = adds up weights within each sex group\n# weighted_count / sum(census_data$PERWT) * 100 = calculates percentage\n# * 100 = converts from decimal to percentage\n\nprint(sex_counts)\n\n# A tibble: 2 √ó 4\n  SEX        sample_count weighted_count percentage\n  &lt;int+lbl&gt;         &lt;int&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n1 1 [Male]        1671915      165759516       49.5\n2 2 [Female]      1733894      169155380       50.5\n\n# print() = displays the results table\n\n# Age distribution\ncensus_data %&gt;%\n  summarise(\n    min_age = min(AGE),\n    max_age = max(AGE),\n    mean_age = weighted.mean(AGE, PERWT),\n    median_age = median(AGE)\n  )\n\n# A tibble: 1 √ó 4\n  min_age                  max_age   mean_age median_age\n  &lt;int+lbl&gt;                &lt;int+lbl&gt;    &lt;dbl&gt;      &lt;int&gt;\n1 0 [Less than 1 year old] 96            39.7         44\n\n# Breaking this down:\n# min(AGE) = finds youngest person\n# max(AGE) = finds oldest person\n# weighted.mean(AGE, PERWT) = calculates average age using weights\n# median(AGE) = finds middle age value"
  },
  {
    "objectID": "assignments/Lab Two.html#part-4-comparing-different-data-sources-10-minutes",
    "href": "assignments/Lab Two.html#part-4-comparing-different-data-sources-10-minutes",
    "title": "CSS Lab Two",
    "section": "Part 4: Comparing Different Data Sources (10 minutes)",
    "text": "Part 4: Comparing Different Data Sources (10 minutes)\n\nUnderstanding Data Types\nWe‚Äôve worked with two very different types of data:\nReddit Data (Social Media) - Semi-structured: Has consistent fields but content varies widely - Real-time: Reflects current conversations and trends - User-generated: Quality and accuracy can vary - No sampling weights: Each post represents itself\nCensus Data (Government Survey) - Highly structured: Standardized questions and coding - Representative sample: Designed to represent the entire population - Professional quality: Rigorous data collection methods - Weighted: Each person represents many others in the population\n\n# Compare the two datasets\ncat(\"=== REDDIT DATA ===\\n\")\n\n=== REDDIT DATA ===\n\ncat(\"Type: Social media posts\\n\")\n\nType: Social media posts\n\ncat(\"Sample size:\", nrow(reddit_data), \"posts\\n\")\n\nSample size: 467 posts\n\ncat(\"Time period: Specific posts about Netflix\\n\")\n\nTime period: Specific posts about Netflix\n\ncat(\"Geographic scope: Unknown (could be global)\\n\\n\")\n\nGeographic scope: Unknown (could be global)\n\ncat(\"=== CENSUS DATA ===\\n\")\n\n=== CENSUS DATA ===\n\ncat(\"Type: Population survey\\n\")\n\nType: Population survey\n\ncat(\"Sample size:\", nrow(census_data), \"people\\n\")\n\nSample size: 3405809 people\n\ncat(\"Represents:\", round(sum(census_data$PERWT)), \"people in the population\\n\")\n\nRepresents: 334914896 people in the population\n\ncat(\"Geographic scope: United States\\n\")\n\nGeographic scope: United States\n\ncat(\"Data collection: Professional survey\\n\")\n\nData collection: Professional survey\n\n# cat() = prints text to console\n# round() = rounds numbers to whole numbers (removes decimals)\n# \\n = creates new lines to format the output nicely"
  },
  {
    "objectID": "assignments/Lab Two.html#part-5-data-source-exploration-15-minutes",
    "href": "assignments/Lab Two.html#part-5-data-source-exploration-15-minutes",
    "title": "CSS Lab Two",
    "section": "Part 5: Data Source Exploration (15 minutes)",
    "text": "Part 5: Data Source Exploration (15 minutes)\n\nLearning About IPUMS USA\nIPUMS (Integrated Public Use Microdata Series) is a project that provides census and survey data for research. Let‚Äôs explore what‚Äôs available:\nVisit: https://usa.ipums.org/usa/\nKey Features: - Free registration with academic email - Access to decades of U.S. census data - Harmonized variables (consistent across years) - Both individual and household-level data\nAvailable Datasets: - Decennial Census: Every 10 years, basic demographics - American Community Survey (ACS): Annual, detailed economics and social data\n- Current Population Survey (CPS): Monthly employment data\nHow IPUMS Works: 1. Select variables you want (age, income, education, etc.) 2. Choose which years/samples 3. Create an ‚Äúextract‚Äù (custom dataset) 4. Download both data file and documentation\n\n\nLearning About Kaggle\nKaggle is a platform for data science with thousands of free datasets.\nVisit: https://www.kaggle.com/datasets\nTypes of Data Available: - Business datasets (sales, marketing, finance) - Sports and gaming data - Social media exports - Government and public datasets - Scientific research data\nBenefits for Students: - No registration required to browse - Real-world datasets - Community discussions about data quality - Examples of data analysis projects\nExample Popular Datasets: - Netflix movies and TV shows - COVID-19 data - Housing prices - Student performance data - Social media sentiment"
  },
  {
    "objectID": "assignments/Lab Two.html#practice-exercises",
    "href": "assignments/Lab Two.html#practice-exercises",
    "title": "CSS Lab Two",
    "section": "Practice Exercises",
    "text": "Practice Exercises\n\nExercise 1: Basic Data Questions\nQuestion 1: How many rows are in the Reddit dataset?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nnrow(reddit_data)\n\n[1] 467\n\n# nrow() counts the number of rows in the dataset\n# Each row represents one Reddit post\n\n\n\n\nQuestion 2: How many columns are in the Census dataset?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nncol(census_data)\n\n[1] 23\n\n# ncol() counts the number of columns in the dataset\n# Each column represents a different variable like age or sex\n\n\n\n\n\n\nExercise 2: Exploring Reddit Data\nQuestion 1: What are the column names in the Reddit dataset?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nnames(reddit_data)\n\n[1] \"title\"        \"score\"        \"id\"           \"subreddit\"    \"url\"         \n[6] \"num_comments\" \"body\"         \"created\"      \"timestamp\"   \n\n# names() shows all column names in the dataset\n# This helps us see what information we have about each post\n\n\n\n\nQuestion 2: What is the highest score in the Reddit data?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nmax(reddit_data$score, na.rm = TRUE)\n\n[1] \"love\"\n\n# max() finds the largest value\n# reddit_data$score selects just the score column\n# The dollar sign operator picks a specific column\n# na.rm = TRUE ignores missing values\n\n\n\n\n\n\nExercise 3: Exploring Census Data\nQuestion 1: What is the youngest age in the Census data?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nmin(census_data$AGE)\n\n&lt;labelled&lt;integer&gt;[1]&gt;: Age\n[1] 0\n\nLabels:\n value                                label\n     0                 Less than 1 year old\n    90            90 (90+ in 1980 and 1990)\n   100              100 (100+ in 1960-1970)\n   112 112 (112+ in the 1980 internal data)\n   115 115 (115+ in the 1990 internal data)\n   999                              Missing\n\n# min() finds the smallest value\n# census_data$AGE selects the age column from census data\n\n\n\n\nQuestion 2: How many people in the sample are exactly 30 years old?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nsum(census_data$AGE == 30)\n\n[1] 41231\n\n# sum() adds up all the TRUE values\n# census_data$AGE == 30 checks if each person age equals 30\n# Two equal signs mean exactly equal to\n# This creates TRUE/FALSE for each person then sum() counts the TRUEs\n\n\n\n\n\n\nExercise 4: Making Simple Comparisons\nQuestion 1: Which dataset is bigger - Reddit or Census?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\n# Count rows in each dataset\nreddit_rows &lt;- nrow(reddit_data)\ncensus_rows &lt;- nrow(census_data)\n\n# Display the counts\ncat(\"Reddit dataset:\", reddit_rows, \"rows\\n\")\n\nReddit dataset: 467 rows\n\ncat(\"Census dataset:\", census_rows, \"rows\\n\")\n\nCensus dataset: 3405809 rows\n\n# Compare them\nif(reddit_rows &gt; census_rows) {\n  cat(\"Reddit dataset is bigger\")\n} else {\n  cat(\"Census dataset is bigger\")\n}\n\nCensus dataset is bigger\n\n# cat() prints text to the screen\n# \\n creates a new line\n# if() checks a condition and does something based on the result\n\n\n\n\nQuestion 2: What is the average age in the Census data?\n\n\n\n\n\n\nReveal Answer\n\n\n\n\n\n\nmean(census_data$AGE)\n\n[1] 43.11174\n\n# mean() calculates the average of all values\n# This adds up all ages and divides by the number of people"
  },
  {
    "objectID": "assignments/Lab Two.html#what-youve-practiced",
    "href": "assignments/Lab Two.html#what-youve-practiced",
    "title": "CSS Lab Two",
    "section": "What You‚Äôve Practiced",
    "text": "What You‚Äôve Practiced\nAfter completing these exercises, you should understand: - How to count rows and columns with nrow() and ncol() - How to find column names with names() - How to find minimum and maximum values with min() and max() - How to calculate averages with mean() - How to count specific values using sum() and double equals - How to compare datasets using simple if statements"
  },
  {
    "objectID": "assignments/Lab Two.html#key-takeaways",
    "href": "assignments/Lab Two.html#key-takeaways",
    "title": "CSS Lab Two",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nWhat We Learned\n\nFile Paths: How to locate and reference files on your computer\nDifferent Data Types: Social media vs government survey data have very different structures\nData Quality: Always check for missing values, outliers, and data errors\nSurvey Weights: Census data uses weights to represent the larger population\nDocumentation: Always document your data sources and methods\n\n\n\nImportant Skills for Data Science\n\nAlways explore your data first before doing analysis\nUnderstand your data source - where did it come from and how was it collected?\nCheck data quality - missing values, duplicates, outliers\nDocument everything - future you will thank present you\nDifferent data requires different approaches - social media data vs survey data need different handling\n\n\n\nNext Steps\n\nPractice loading different types of files (CSV, Excel, JSON)\nExplore more datasets on Kaggle\nLearn about data cleaning and preparation\nUnderstand sampling and bias in different data sources\n\nRemember: Good data science starts with understanding your data!"
  },
  {
    "objectID": "resources/software.html#testing-your-setup",
    "href": "resources/software.html#testing-your-setup",
    "title": "Software Setup",
    "section": "Testing Your Setup",
    "text": "Testing Your Setup"
  },
  {
    "objectID": "resources/software.html#getting-help",
    "href": "resources/software.html#getting-help",
    "title": "Software Setup",
    "section": "Getting Help",
    "text": "Getting Help\n\nCourse discussion forum: [ADD LINK]\nOffice hours: [ADD TIMES]\nTA sessions: [ADD TIMES]"
  },
  {
    "objectID": "resources/tutorials.html",
    "href": "resources/tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Tutorial 1\nTutorial 2\nTutorial 3"
  },
  {
    "objectID": "resources/tutorials.html#category-1-tutorials",
    "href": "resources/tutorials.html#category-1-tutorials",
    "title": "Tutorials",
    "section": "",
    "text": "Tutorial 1\nTutorial 2\nTutorial 3"
  },
  {
    "objectID": "resources/tutorials.html#category-2-tutorials",
    "href": "resources/tutorials.html#category-2-tutorials",
    "title": "Tutorials",
    "section": "[CATEGORY 2] Tutorials",
    "text": "[CATEGORY 2] Tutorials\n\nTutorial 1\nTutorial 2\nTutorial 3"
  },
  {
    "objectID": "resources/tutorials.html#video-tutorials",
    "href": "resources/tutorials.html#video-tutorials",
    "title": "Tutorials",
    "section": "Video Tutorials",
    "text": "Video Tutorials\n\nVideo Resource 1\nVideo Resource 2"
  },
  {
    "objectID": "resources/data.html",
    "href": "resources/data.html",
    "title": "Data Sources",
    "section": "",
    "text": "[Source Name]: [URL or description]\n[Source Name]: [URL or description]\n[Source Name]: [URL or description]"
  },
  {
    "objectID": "resources/data.html#data-category-1",
    "href": "resources/data.html#data-category-1",
    "title": "Data Sources",
    "section": "",
    "text": "[Source Name]: [URL or description]\n[Source Name]: [URL or description]\n[Source Name]: [URL or description]"
  },
  {
    "objectID": "resources/data.html#data-category-2",
    "href": "resources/data.html#data-category-2",
    "title": "Data Sources",
    "section": "[DATA CATEGORY 2]",
    "text": "[DATA CATEGORY 2]\n\n[Source Name]: [URL or description]\n[Source Name]: [URL or description]\n[Source Name]: [URL or description]"
  },
  {
    "objectID": "resources/data.html#data-ethics-and-access",
    "href": "resources/data.html#data-ethics-and-access",
    "title": "Data Sources",
    "section": "Data Ethics and Access",
    "text": "Data Ethics and Access\n\n\nBest Practices\n\n[Best practice 1]\n[Best practice 2]\n[Best practice 3]\n\n\n\nEthical Considerations\n\n[Ethical consideration 1]\n[Ethical consideration 2]\n[Ethical consideration 3]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SOC 480: Advanced Research Methods in Sociology - Computational Social Science",
    "section": "",
    "text": "Instructor: Angelita Repetto\nEmail: arepetto@msu.edu\nOffice Hours: Thursday 12:30-2:30 In-person: Berkey Hall 433A Zoom link: https://ucdavis.zoom.us/j/8795657500\nLocation: South Kedzie Hall Room 222\nTime: Tuesday/Thursday at 10:20 AM-11:40 AM\nWelcome to the course website for SOC 480: Advanced Research Methods in Sociology!\nOn this website you will find:\n\nSyllabus\nShchedule\nAssignment guidelines\nLabs\nR related material\n\nOn Canvas you will find:\n\nReading material\nData for labs and projects\nSubmit assignments\nGrades"
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "SOC 480: Advanced Research Methods in Sociology - Computational Social Science",
    "section": "",
    "text": "Instructor: Angelita Repetto\nEmail: arepetto@msu.edu\nOffice Hours: Thursday 12:30-2:30 In-person: Berkey Hall 433A Zoom link: https://ucdavis.zoom.us/j/8795657500\nLocation: South Kedzie Hall Room 222\nTime: Tuesday/Thursday at 10:20 AM-11:40 AM\nWelcome to the course website for SOC 480: Advanced Research Methods in Sociology!\nOn this website you will find:\n\nSyllabus\nShchedule\nAssignment guidelines\nLabs\nR related material\n\nOn Canvas you will find:\n\nReading material\nData for labs and projects\nSubmit assignments\nGrades"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "SOC 480: Advanced Research Methods in Sociology - Computational Social Science",
    "section": "Course Description",
    "text": "Course Description\nThis course provides an overview of computational social science methods and their application to sociological research questions. Students will learn to implement these methods using R programming. Digital technology has fundamentally transformed both societal functioning and social research methodologies. As society becomes increasingly dependent on digital infrastructure and internet connectivity, vast digital footprints emerge that offer unprecedented research opportunities. These footprints encompass credit card transactions, social media interactions, GPS tracking data, and cellular communication records, among other sources. The exponential growth in data scale and accessibility has driven substantial advances in computational methods for analyzing these complex datasets. Social science disciplines now routinely leverage these resources to investigate pressing questions about contemporary society.\nThis course examines diverse data sources and analytical methods, explores the types of research questions they can address, and provides hands-on training in conducting these analyses using R. Students will gain experience with data collection, processing, visualization, and statistical modeling techniques commonly employed in computational social science research.\nThe course culminates in a comprehensive final project where students apply multiple computational methods to investigate a sociological research question of their choosing. This project requires students to conduct original analysis, produce a formal research paper, and present their findings to the class, integrating the theoretical and technical skills developed throughout the semester."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "SOC 480: Advanced Research Methods in Sociology - Computational Social Science",
    "section": "Getting Started",
    "text": "Getting Started\n\nReview the syllabus\nCheck the schedule for upcoming assignments\nSet up your software environment\nR Video for Beginners"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course provides an overview of computational social science methods and their application to sociological research questions. Students will learn to implement these methods using R programming.\nDigital technology has fundamentally transformed both societal functioning and social research methodologies. As society becomes increasingly dependent on digital infrastructure and internet connectivity, vast digital footprints emerge that offer unprecedented research opportunities. These footprints encompass credit card transactions, social media interactions, GPS tracking data, and cellular communication records, among other sources. The exponential growth in data scale and accessibility has driven substantial advances in computational methods for analyzing these complex datasets. Social science disciplines now routinely leverage these resources to investigate pressing questions about contemporary society.\nThis course examines diverse data sources and analytical methods, explores the types of research questions they can address, and provides hands-on training in conducting these analyses using R. Students will gain experience with data collection, processing, visualization, and statistical modeling techniques commonly employed in computational social science research.\nThe course culminates in a comprehensive final project where students apply multiple computational methods to investigate a sociological research question of their choosing. This project requires students to conduct original analysis, produce a formal research paper, and present their findings to the class, integrating the theoretical and technical skills developed throughout the semester."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\n\n\n\n\n\n\n\n\nComponent\nWeight\nDetails\n\n\n\n\nClass Attendance\n25%\n- Each class is 1% up to 25%- You get two free misses as there are 27 classes total\n\n\nLab Work\n25%\n- 2.5% per lab assignment submitted\n\n\nFinal Project\n50%\n- Final Project Proposal: 10%- Final Project Presentation: 20%- Final Project Paper: 20%"
  },
  {
    "objectID": "syllabus.html#attendance-policy",
    "href": "syllabus.html#attendance-policy",
    "title": "Syllabus",
    "section": "Attendance Policy",
    "text": "Attendance Policy\nAttendance in class is mandatory. You can miss a maximum of two classes with no penalty. I recommend saving these for if you are ill."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Syllabus",
    "section": "Readings",
    "text": "Readings\nAssigned readings must be completed before class on Tuesday."
  },
  {
    "objectID": "syllabus.html#lab-work",
    "href": "syllabus.html#lab-work",
    "title": "Syllabus",
    "section": "Lab Work",
    "text": "Lab Work\nThere will be in class lab assignments that must be submitted at the end of lab. You will submit your R markdown file with the code from lab and your answers for the lab questions which includes the code and a written response of the answer. These will be graded on completion and effort."
  },
  {
    "objectID": "syllabus.html#final-project",
    "href": "syllabus.html#final-project",
    "title": "Syllabus",
    "section": "Final Project",
    "text": "Final Project\nThe primary component of your grade is the final project. This will be a research paper exploring a sociological topic using computational methods learned during the course. This can be completed individually or in pairs. This will be broken down into several components:\n\nProject Proposal (10%)\nFinal project presentation (20%)\nFinal project paper (30%)\n\nThe final paper should be 8-10 pages, times new roman, 12pt font, double spaced, with no spaces between paragraphs."
  },
  {
    "objectID": "syllabus.html#email-etiquette-policy",
    "href": "syllabus.html#email-etiquette-policy",
    "title": "Syllabus",
    "section": "Email Etiquette Policy",
    "text": "Email Etiquette Policy\nStudents are required to use professional email communication when contacting the instructor or teaching assistants. All course-related emails must adhere to the following guidelines: - Use your official university email account. - Include a clear and specific subject line (e.g., ‚ÄúSOC 140: Question on Assignment 2‚Äù). - Begin with a professional salutation (e.g., ‚ÄúDear Professor Repetto‚Äù). - Include well wishes. - State your full name and the course title in the body of the message. - Communicate in a concise, respectful, and professional manner. - Do not use slang, abbreviations, or overly casual language. - Allow 24‚Äì48 hours for a response on weekdays. Emails sent on weekends or holidays will be addressed on the next business day. - Consult the syllabus and course materials before submitting questions. - Failure to follow these guidelines may result in delayed or no response.\nExample of a Proper Email\nSubject: SOC 140: Clarification on Assignment 2 Instructions\nDear Professor Repetto,\nI hope this email finds you well.\nMy name is Jane Doe, and I am enrolled in SOC 140 this semester. I have a question regarding the instructions for Assignment 2. Specifically, I would like clarification on whether we should include both tables and figures in the results section, or if one format is sufficient.\nThank you for your time and assistance.\nSincerely, Jordan Smith\nExample of a Poor Email\nSubject: Question\nhey, I don‚Äôt get the homework. what r we supposed to do? can u explain? thx"
  },
  {
    "objectID": "syllabus.html#late-work-policy",
    "href": "syllabus.html#late-work-policy",
    "title": "Syllabus",
    "section": "Late Work Policy",
    "text": "Late Work Policy\nWork that is submitted late will recieve a 10% penalty per day. After 5 days it will no longer be accepted. If you are in need of an extension, please reach out one week at least three days ahead of time with an explanation as to why an extension is needed and the length of an extension that you are requesting. No extensions are possible for the final paper."
  },
  {
    "objectID": "syllabus.html#academic-integrity-policy",
    "href": "syllabus.html#academic-integrity-policy",
    "title": "Syllabus",
    "section": "Academic Integrity Policy",
    "text": "Academic Integrity Policy\n‚ÄúAs a Spartan, I will strive to uphold values of the highest ethical standard. I will practice honesty in my work, foster honesty in my peers, and take pride in knowing that honor is worth more than grades. I will carry these values beyond my time as a student at Michigan State University, continuing the endeavor to build personal integrity in all that I do.‚Äù\nPlagarism is when you present someone else‚Äôs work or ideas as your own, wihtout giving proper credit to the original source. When you use generative AI to help write papers, you may accidentally commit plagarism because the text produced is not originally yours. Using generative AI to write course assignments is not permitted. All sources cited in papers must be properly cited using ASA format."
  },
  {
    "objectID": "syllabus.html#ai-policy",
    "href": "syllabus.html#ai-policy",
    "title": "Syllabus",
    "section": "AI Policy",
    "text": "AI Policy\nIn this course, AI is not permitted during class to help with lab assignments. Although AI is a useful tool for coding, it necessitates an understanding of how to code to be utilized properly. However, AI can be used to assist with coding outside of class for the final project after the baseline understanding of coding is built throughout class. Additionally, you cannot use AI to generate content for the final paper, but you can use it to copy edit human written text. This means you may submit a completed paper and specifically ask it to ‚Äúcopy edit.‚Äù You cannot ask it to expand on your text, write a section for you, etc.\nIf you use AI, you will be required to submit a memo disucssing how it was used, how you utiized the changes it made, what it did well, and what it did not do well, as well as a log of chats."
  },
  {
    "objectID": "syllabus.html#required-materials",
    "href": "syllabus.html#required-materials",
    "title": "Syllabus",
    "section": "Required Materials",
    "text": "Required Materials\nWe will be using R and R studio in this class. This is a free software that you can use in this classroom and download onto your personal computers to work on your projects at home."
  },
  {
    "objectID": "syllabus.html#course-schedule",
    "href": "syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\n\n\n\n\n\n\n\nWeek\nDate\nDay\nTopic\n\n\n\n\nWeek One\n8/26/25\nTuesday\nIntroduction to the Course and CSS\n\n\n\n8/28/25\nThursday\nIntroduction to Sociology\n\n\nWeek Two\n9/2/25\nTuesday\nIntroduction to R: Part One\n\n\n\n9/4/25\nThursday\nIntroduction to R: Part Two\n\n\nWeek Three\n9/9/25\nTuesday\nData Sources: Lecture\n\n\n\n9/11/25\nThursday\nData Sources: R Lab\n\n\nWeek Four\n9/16/25\nTuesday\nNatural Language Processing: Lecture\n\n\n\n9/18/25\nThursday\nNatural Language Processing: R Lab\n\n\nWeek Five\n9/23/25\nTuesday\nSocial Network Analysis: Lecture\n\n\n\n9/25/25\nThursday\nSocial Network Analysis: R Lab\n\n\nWeek Six\n9/30/25\nTuesday\nAgent Based Modeling: Lecture\n\n\n\n10/2/25\nThursday\nAgent Based Modeling: R Lab\n\n\nWeek Seven\n10/7/25\nTuesday\nLLMs and AI: Lecture\n\n\n\n10/9/25\nThursday\nLLMs and AI: R Lab\n\n\nWeek Eight\n10/14/25\nTuesday\nSupervised Machine Learning: Lecture\n\n\n\n10/16/25\nThursday\nSupervised Machine Learning: R Lab\n\n\nWeek Nine\n10/21/25\nTuesday\nFall Break\n\n\n\n10/23/25\nThursday\nUnsupervised Machine Learning: Lecture\n\n\nWeek Ten\n10/28/25\nTuesday\nUnsupervised Machine Learning: R Lab\n\n\n\n10/30/25\nThursday\nProject Ideas Workshop\n\n\nWeek Eleven\n11/4/25\nTuesday\nSpatial Segregation: Lecture\n\n\n\n11/6/25\nThursday\nSpatial Segregation: Lab\n\n\nWeek Twelve\n11/11/25\nTuesday\nProject Workshop\n\n\n\n11/13/25\nThursday\nProject Workshop\n\n\nWeek Thirteen\n11/18/25\nTuesday\nProject Workshop\n\n\n\n11/20/25\nThursday\nProject Workshop\n\n\nWeek Fourteen\n11/25/25\nTuesday\nNo class - practice final project presentations and additional office hours\n\n\n\n11/27/25\nThursday\nThanksgiving Break\n\n\nWeek Fifteen\n12/2/25\nTuesday\nProject Presentations\n\n\n\n12/4/25\nThursday\nProject Presentations\n\n\nFinals Week\n12/9/25\nTuesday\nNo class\n\n\n\n12/11/25\nThursday\nOptional class for questions"
  },
  {
    "objectID": "Lab One Part Two.html",
    "href": "Lab One Part Two.html",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "Let‚Äôs work with R‚Äôs built-in datasets and explore more advanced data manipulation techniques.\n\n\n#| echo: true\n#| eval: false\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\n# Aggregating data\n# Average measurements by species\naggregate(. ~ Species, data = iris, FUN = mean)\n\n# Multiple statistics\naggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\nprint(\"Random sample of iris data:\")\nprint(iris_sample)\n\n# Aggregating data\n# Average measurements by species\nprint(\"Average measurements by species:\")\nprint(aggregate(. ~ Species, data = iris, FUN = mean))\n\n# Multiple statistics\nprint(\"MPG and HP statistics by cylinder:\")\nprint(aggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x))))\n\n\n\n\n\n\n\nR‚Äôs plotting capabilities are extensive. Let‚Äôs explore various types of plots.\n\n\n#| echo: true\n#| eval: false\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\n\nLet‚Äôs perform various statistical tests and create models.\n\n\n#| echo: true\n#| eval: false\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\n\nLearning to write functions and use control structures makes R much more powerful.\n\n\n#| echo: true\n#| eval: false\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)"
  },
  {
    "objectID": "Lab One Part Two.html#part-2-data-analysis-visualization-and-programming-60-minutes",
    "href": "Lab One Part Two.html#part-2-data-analysis-visualization-and-programming-60-minutes",
    "title": "Lab One: Part Two",
    "section": "",
    "text": "Let‚Äôs work with R‚Äôs built-in datasets and explore more advanced data manipulation techniques.\n\n\n#| echo: true\n#| eval: false\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Load the iris dataset\ndata(iris)\ndata(mtcars)\n\n# Explore iris dataset\nhead(iris)\nstr(iris)\nsummary(iris)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# More detailed exploration\nsapply(iris[, 1:4], mean)  # Apply mean to numeric columns\nsapply(iris[, 1:4], sd)    # Standard deviation\nsapply(iris[, 1:4], range) # Range for each column\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Exploring categorical variables\ntable(iris$Species)\nprop.table(table(iris$Species))  # Proportions\n\n# Cross-tabulation with mtcars\ntable(mtcars$cyl, mtcars$gear)\nprop.table(table(mtcars$cyl, mtcars$gear), margin = 1)  # Row proportions\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Advanced filtering and subsetting\n# Multiple conditions\nlarge_setosa &lt;- iris[iris$Species == \"setosa\" & iris$Sepal.Length &gt; 5, ]\nefficient_powerful &lt;- mtcars[mtcars$mpg &gt; 20 & mtcars$hp &gt; 100, ]\n\n# Using %in% operator\nselected_species &lt;- iris[iris$Species %in% c(\"setosa\", \"versicolor\"), ]\n\nprint(\"Large setosa flowers:\")\nprint(large_setosa)\nprint(\"Efficient and powerful cars:\")\nprint(efficient_powerful)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\n# Aggregating data\n# Average measurements by species\naggregate(. ~ Species, data = iris, FUN = mean)\n\n# Multiple statistics\naggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Sampling data\nsample_rows &lt;- sample(nrow(iris), 10)  # Random 10 row indices\niris_sample &lt;- iris[sample_rows, ]\n\nprint(\"Random sample of iris data:\")\nprint(iris_sample)\n\n# Aggregating data\n# Average measurements by species\nprint(\"Average measurements by species:\")\nprint(aggregate(. ~ Species, data = iris, FUN = mean))\n\n# Multiple statistics\nprint(\"MPG and HP statistics by cylinder:\")\nprint(aggregate(cbind(mpg, hp) ~ cyl, data = mtcars, \n          FUN = function(x) c(mean = mean(x), sd = sd(x))))\n\n\n\n\n\n\n\nR‚Äôs plotting capabilities are extensive. Let‚Äôs explore various types of plots.\n\n\n#| echo: true\n#| eval: false\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Basic plots with customization\n# Histogram with better styling\nhist(iris$Sepal.Length, \n     main = \"Distribution of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Frequency\",\n     col = \"lightblue\",\n     border = \"darkblue\",\n     breaks = 15)\n\n# Add vertical line for mean\nabline(v = mean(iris$Sepal.Length), col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = \"Mean\", col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Scatter plot with groups\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     main = \"Sepal Length vs Width by Species\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Sepal Width (cm)\",\n     col = c(\"red\", \"blue\", \"green\")[iris$Species],\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = levels(iris$Species),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19)\n\n# Add trend line\nabline(lm(Sepal.Width ~ Sepal.Length, data = iris), col = \"black\", lwd = 2)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Box plots\nboxplot(Sepal.Length ~ Species, data = iris,\n        main = \"Sepal Length by Species\",\n        xlab = \"Species\",\n        ylab = \"Sepal Length (cm)\",\n        col = c(\"red\", \"blue\", \"green\"),\n        notch = TRUE)  # Show confidence intervals\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Multiple box plots\npar(mfrow = c(2, 2))  # 2x2 layout\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightblue\")\nboxplot(hp ~ cyl, data = mtcars, main = \"HP by Cylinders\", col = \"lightgreen\")\nboxplot(wt ~ cyl, data = mtcars, main = \"Weight by Cylinders\", col = \"lightcoral\")\nboxplot(qsec ~ cyl, data = mtcars, main = \"Quarter Mile Time by Cylinders\", col = \"lightyellow\")\npar(mfrow = c(1, 1))  # Reset layout\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# More advanced plots\n# Pairs plot (scatter plot matrix)\npairs(iris[, 1:4], \n      main = \"Iris Dataset - Pairwise Relationships\",\n      col = c(\"red\", \"blue\", \"green\")[iris$Species],\n      pch = 19)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Density plots\nplot(density(iris$Sepal.Length), \n     main = \"Density Plot of Sepal Length\",\n     xlab = \"Sepal Length (cm)\",\n     ylab = \"Density\",\n     col = \"blue\",\n     lwd = 2)\n\n# Add density lines for each species\nspecies_colors &lt;- c(\"red\", \"blue\", \"green\")\nfor(i in 1:3) {\n  species_data &lt;- iris[iris$Species == levels(iris$Species)[i], \"Sepal.Length\"]\n  lines(density(species_data), col = species_colors[i], lwd = 2)\n}\nlegend(\"topright\", legend = levels(iris$Species), col = species_colors, lwd = 2)\n\n\n\n\n\n\n\nLet‚Äôs perform various statistical tests and create models.\n\n\n#| echo: true\n#| eval: false\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Descriptive statistics\n# Custom summary function\ndescribe_variable &lt;- function(x) {\n  c(mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    sd = sd(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    q25 = quantile(x, 0.25, na.rm = TRUE),\n    q75 = quantile(x, 0.75, na.rm = TRUE))\n}\n\ndescribe_variable(iris$Sepal.Length)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Correlation analysis\n# Correlation matrix\ncor_matrix &lt;- cor(iris[, 1:4])\nprint(round(cor_matrix, 2))\n\n# Correlation test\ncor.test(iris$Sepal.Length, iris$Sepal.Width)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Hypothesis testing\n# t-test: comparing two groups\nsetosa_sepal &lt;- iris[iris$Species == \"setosa\", \"Sepal.Length\"]\nversicolor_sepal &lt;- iris[iris$Species == \"versicolor\", \"Sepal.Length\"]\n\nt_test_result &lt;- t.test(setosa_sepal, versicolor_sepal)\nprint(t_test_result)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# ANOVA: comparing multiple groups\nanova_result &lt;- aov(Sepal.Length ~ Species, data = iris)\nsummary(anova_result)\n\n# Post-hoc test\nTukeyHSD(anova_result)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Linear regression\n# Simple linear regression\nmodel1 &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model1)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Multiple linear regression\nmodel2 &lt;- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model2)\n\n# Model comparison\nanova(model1, model2)\n\n# Predictions\nnew_car &lt;- data.frame(wt = 3.0, hp = 150, cyl = 6)\npredicted_mpg &lt;- predict(model2, new_car)\nprint(paste(\"Predicted MPG:\", round(predicted_mpg, 2)))\n\n\n\n\n\n\n\nLearning to write functions and use control structures makes R much more powerful.\n\n\n#| echo: true\n#| eval: false\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Writing custom functions\ngrade_to_letter &lt;- function(numeric_grade) {\n  if (numeric_grade &gt;= 90) {\n    return(\"A\")\n  } else if (numeric_grade &gt;= 80) {\n    return(\"B\")\n  } else if (numeric_grade &gt;= 70) {\n    return(\"C\")\n  } else if (numeric_grade &gt;= 60) {\n    return(\"D\")\n  } else {\n    return(\"F\")\n  }\n}\n\n# Test the function\ngrade_to_letter(85)\ngrade_to_letter(92)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Vectorized version\ngrade_to_letter_vec &lt;- function(grades) {\n  ifelse(grades &gt;= 90, \"A\",\n         ifelse(grades &gt;= 80, \"B\",\n                ifelse(grades &gt;= 70, \"C\",\n                       ifelse(grades &gt;= 60, \"D\", \"F\"))))\n}\n\ntest_grades &lt;- c(95, 87, 78, 65, 45)\ngrade_to_letter_vec(test_grades)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# For loop\nfibonacci &lt;- function(n) {\n  if (n &lt;= 1) return(n)\n  \n  fib_seq &lt;- numeric(n)\n  fib_seq[1] &lt;- 0\n  fib_seq[2] &lt;- 1\n  \n  for (i in 3:n) {\n    fib_seq[i] &lt;- fib_seq[i-1] + fib_seq[i-2]\n  }\n  \n  return(fib_seq)\n}\n\nfibonacci(10)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# While loop example\ncount_down &lt;- function(start) {\n  current &lt;- start\n  result &lt;- c()\n  \n  while (current &gt; 0) {\n    result &lt;- c(result, current)\n    current &lt;- current - 1\n  }\n  \n  return(result)\n}\n\ncount_down(5)\n\n\n\n\n\n\n#| echo: true\n#| eval: false\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)\n\n\n\n\n\n\nShow Output\n\n\n\n\n\n#| echo: false\n#| eval: true\n# Apply family functions (more efficient than loops)\n# lapply: apply function to list elements\nnumbers &lt;- list(a = 1:5, b = 6:10, c = 11:15)\nlapply(numbers, mean)\n\n# sapply: simplified apply\nsapply(numbers, mean)\n\n# mapply: multivariate apply\nmapply(function(x, y) x + y, 1:3, 4:6)"
  },
  {
    "objectID": "Lab One Part Two.html#practice-exercises",
    "href": "Lab One Part Two.html#practice-exercises",
    "title": "Lab One: Part Two",
    "section": "Practice Exercises",
    "text": "Practice Exercises\nüîç Exercise 2a: Create a function that calculates the coefficient of variation (CV = sd/mean) for a numeric vector. Test it on the Sepal.Length column of the iris dataset for each species.\n\n\n\n\n\n\nClick to see Exercise 2a Answer\n\n\n\n\n\n#| echo: true\n#| eval: true\n# Create coefficient of variation function\ncoeff_variation &lt;- function(x) {\n  cv &lt;- sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\n  return(cv)\n}\n\n# Test on Sepal.Length for each species\nspecies_list &lt;- levels(iris$Species)\ncv_results &lt;- sapply(species_list, function(species) {\n  species_data &lt;- iris[iris$Species == species, \"Sepal.Length\"]\n  coeff_variation(species_data)\n})\n\nprint(\"Coefficient of Variation for Sepal.Length by Species:\")\nprint(round(cv_results, 4))\n\n# Alternative approach using aggregate\ncv_by_species &lt;- aggregate(Sepal.Length ~ Species, data = iris, \n                          FUN = function(x) sd(x)/mean(x))\nprint(\"Using aggregate function:\")\nprint(cv_by_species)\nThe coefficient of variation measures relative variability. Lower values indicate less variability relative to the mean. Setosa has the lowest CV, indicating more consistent sepal lengths within that species.\n\n\n\nüîç Exercise 2b: Using the mtcars dataset, create a comprehensive analysis that includes:\n\n\nA summary of the data\n\nA correlation matrix of all numeric variables\n\nA linear model predicting mpg from weight and horsepower\n\nA visualization showing the relationship between weight and mpg with different colors for number of cylinders\n\n\n::: {.callout-note collapse=‚Äútrue‚Äù}"
  },
  {
    "objectID": "Lab One Part Two.html#click-to-see-exercise-2b-answer",
    "href": "Lab One Part Two.html#click-to-see-exercise-2b-answer",
    "title": "Lab One: Part Two",
    "section": "Click to see Exercise 2b Answer",
    "text": "Click to see Exercise 2b Answer\n#| echo: true\n#| eval: true\n# Comprehensive mtcars analysis\n\n# 1. Summary of the data\nprint(\"=== MTCARS DATASET SUMMARY ===\")\nprint(summary(mtcars))\nprint(paste(\"Dataset dimensions:\", nrow(mtcars), \"rows,\", ncol(mtcars), \"columns\"))\n\n# 2. Correlation matrix of all numeric variables\nprint(\"\\n=== CORRELATION MATRIX ===\")\ncor_matrix &lt;- cor(mtcars)\nprint(round(cor_matrix, 2))\n\n# 3. Linear model predicting mpg from weight and horsepower\nprint(\"\\n=== LINEAR REGRESSION MODEL ===\")\nmpg_model &lt;- lm(mpg ~ wt + hp, data = mtcars)\nprint(summary(mpg_model))\n\n# Model interpretation\nr_squared &lt;- summary(mpg_model)$r.squared\nprint(paste(\"R-squared:\", round(r_squared, 3)))\nprint(paste(\"The model explains\", round(r_squared * 100, 1), \"% of the variance in MPG\"))\n\n# 4. Visualization: Weight vs MPG colored by cylinders\nprint(\"\\n=== VISUALIZATION ===\")\n# Create color vector for cylinders\ncyl_colors &lt;- c(\"red\", \"blue\", \"green\")[as.factor(mtcars$cyl)]\n\nplot(mtcars$wt, mtcars$mpg,\n     main = \"MPG vs Weight by Number of Cylinders\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     col = cyl_colors,\n     pch = 19,\n     cex = 1.2)\n\n# Add legend\nlegend(\"topright\", \n       legend = paste(sort(unique(mtcars$cyl)), \"cylinders\"),\n       col = c(\"red\", \"blue\", \"green\"),\n       pch = 19,\n       title = \"Engine\")\n\n# Add regression line\nabline(lm(mpg ~ wt, data = mtcars), col = \"black\", lwd = 2, lty = 2)\n\n# Add text annotation\ntext(4.5, 30, paste(\"R¬≤ =\", round(summary(lm(mpg ~ wt, data = mtcars))$r.squared, 3)),\n     cex = 0.9, col = \"black\")\nKey Findings:\n\n\nCorrelation: Weight (wt) and horsepower (hp) are strongly negatively correlated with MPG\n\nModel: The regression model explains about 83% of MPG variance using weight and horsepower\n\nVisualization: Cars with fewer cylinders tend to be lighter and more fuel-efficient\n\nRelationship: Clear negative relationship between weight and MPG across all cylinder groups :::"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Subject to change - check here for most up to date class schedule.\n\n\nTuesday - 8/26/25\nTopics:\n\nIntroduction to the course\nIntroduction to Computational Social Science\n\nThursday - 8/28/25\nTopics:\n\nIntroduction to Sociology\n\nReadings:\n\nhttps://www.asanet.org/wp-content/uploads/savvy/introtosociology/Documents/Field%20of%20sociology 033108.htm\nCioffi-Revilla, Claudio. 2010. ‚ÄúComputational Social Science.‚Äù Wiley Interdisciplinary Reviews: Computational Statistics 2(3):259‚Äì71.\nEdelmann, A., Wolff, T., Montagne, D., & Bail, C. A. (2020). Computational social science and sociology. Annual Review of Sociology, 46, 61-81.\n\n\n\n\n\nTuesday - 9/2/25\nTopics:\n\nIntroduction to R - Part One\n\nDue:\n\nIntroduction worksheet.\n\nThursday - 9/4/25\nTopics:\n\nIntroduction to R - Part Two\n\nDue:\n\nDownload R and R Studio on your personal laptops.\n\n\n\n\n\nTuesday - 9/9/25\nTopics:\n\nData Sources - Lecture\n\nReadings:\n\nLazer, David, and Jason Radford. 2017. ‚ÄúData ex Machina: Introduction to Big Data.‚Äù Annual Review of Sociology 43: 19-39\n\nThursday - 9/11/25\nTopics:\n\nData Sources - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/16/25\nTopics:\n\nNatural Language Processing - Lecture\n\nReadings:\n\nBail, Christopher A., Taylor W. Brown, and Marcus Mann. 2017. ‚ÄúChanneling Hearts and Minds: Advocacy Organizations, Cognitive-Emotional Currents, and Public Conversation.‚Äù American Sociological Review 82(6):1188‚Äì1213.\n\nThursday - 9/18/25\nTopics:\n\nNatural Language Processing - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/23/25\nTopics:\n\nSocial Network Analysis - Lecture\n\nReadings:\n\nTabassum, Shazia, Fabiola S. Pereira, Sofia Fernandes, and Jo√£o Gama. 2018. ‚ÄúSocial Network Analysis: An Overview.‚Äù WIREs Data Mining and Knowledge Discovery 8(5).\n\nThursday - 9/25/25\nTopics:\n\nSocial Network Analysis - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/30/25\nTopics:\n\nAgent Based Modeling - Lecture\n\nReadings:\n\nDacrema, Eugenio, and Stefano Benati. 2020. ‚ÄúThe Mechanics of Contentious Politics: An Agent-Based Modeling Approach.‚Äù The Journal of Mathematical Sociology 44(3):163‚Äì98. doi:10.1080/0022250X.2020.1753187.\n\nThursday - 10/2/25\nTopics:\n\nAgent Based Modeling - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/7/25\nTopics:\n\nLLMs and AI - Lecture\n\nReadings:\n\nDavidson, Thomas, and Daniel Karell. 2025. ‚ÄúIntegrating Generative Artificial Intelligence into Social Science Research: Measurement, Prompting, and Simulation.‚Äù Sociological Methods & Research 54(3):775‚Äì93. doi:10.1177/00491241251339184.\n\nThursday - 10/9/25\nTopics:\n\nLLMs and AI - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/14/25\nTopics:\n\nSupervised Machine Learning - Lecture\n\nReadings:\n\n[READINGS]\n\nThursday - 10/16/25\nTopics:\n\nSupervised Machine Learning - Lab\n\nReadings:\n\n[READINGS]\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/21/25 [No Class - Fall Break]\nThursday - 10/23/25\nTopics:\n\nUnsupervised Machine Learning - Guest Lecture\n\nReadings:\n\n[READINGS]\n\nDue:\n\nNothing due this week.\n\n\n\n\nTuesday - 10/28/25\nTopics:\n\nUnsupervised Machine Learning - Lab\n\nReadings:\n\n[READINGS]\n\nThursday - 10/30/25\nTopics:\n\nProject Ideas Workshop\n\nReadings:\n\n[READINGS]\n\nDue:\n\nSubmit lab at the end of class on Thursday.\nProject proposals due on Canvas at 11/5/25 11:59 pm.\n\n\n\n\nTuesday - 11/4/25\nTopics:\n\nSpatial Segregation - Lecture\n\nReadings:\n\nBrazil, N. (2017). Spatial variation in the hispanic paradox: Mortality rates in new and established hispanic US destinations. Population, Space and Place, 23(1), e1968.\nCrowder, Kyle and Scott J. South. 2008.‚ÄúSpatial Dynamics of White Flight: The Effects of Local and Extralocal Racial Conditions on Neighborhood Out-Migration.‚Äù American Sociological Review 73(5):792‚Äì812.\n\nThursday - 11/6/25\nTopics:\n\nSpatial Segregation - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 11/11/25\nTopics:\n\nProject workshop\n\nThursday - 11/13/25\nTopics:\n\nProject workshop\n\n\n\n\nTuesday - 11/18/25\nTopics:\n\nProject workshop\n\nThursday - 11/120/25\nTopics:\n\nProject workshop\n\n\n\n\nTuesday - 11/18/25\n\nPractice presentations at home\nAdditional zoom office hours for project questions\n\nThursday - 11/20/25\n\nThanksgiving\n\n\n\n\nTuesday - 11/4/25\nTopics:\n\nProject Presentations\n\nThursday - 11/6/25\nTopics:\n\nProject Presentations\nProject Presentations\n\nDue:\n\nSubmit presentation slides on Monday 12/1/25 at 5 pm.\n\n\n\n\nThursday - 12/11/25\nDue:\n\nSubmit final papers 12/11/25 at 11:59."
  },
  {
    "objectID": "schedule.html#course-schedule",
    "href": "schedule.html#course-schedule",
    "title": "Schedule",
    "section": "",
    "text": "Subject to change - check here for most up to date class schedule.\n\n\nTuesday - 8/26/25\nTopics:\n\nIntroduction to the course\nIntroduction to Computational Social Science\n\nThursday - 8/28/25\nTopics:\n\nIntroduction to Sociology\n\nReadings:\n\nhttps://www.asanet.org/wp-content/uploads/savvy/introtosociology/Documents/Field%20of%20sociology 033108.htm\nCioffi-Revilla, Claudio. 2010. ‚ÄúComputational Social Science.‚Äù Wiley Interdisciplinary Reviews: Computational Statistics 2(3):259‚Äì71.\nEdelmann, A., Wolff, T., Montagne, D., & Bail, C. A. (2020). Computational social science and sociology. Annual Review of Sociology, 46, 61-81.\n\n\n\n\n\nTuesday - 9/2/25\nTopics:\n\nIntroduction to R - Part One\n\nDue:\n\nIntroduction worksheet.\n\nThursday - 9/4/25\nTopics:\n\nIntroduction to R - Part Two\n\nDue:\n\nDownload R and R Studio on your personal laptops.\n\n\n\n\n\nTuesday - 9/9/25\nTopics:\n\nData Sources - Lecture\n\nReadings:\n\nLazer, David, and Jason Radford. 2017. ‚ÄúData ex Machina: Introduction to Big Data.‚Äù Annual Review of Sociology 43: 19-39\n\nThursday - 9/11/25\nTopics:\n\nData Sources - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/16/25\nTopics:\n\nNatural Language Processing - Lecture\n\nReadings:\n\nBail, Christopher A., Taylor W. Brown, and Marcus Mann. 2017. ‚ÄúChanneling Hearts and Minds: Advocacy Organizations, Cognitive-Emotional Currents, and Public Conversation.‚Äù American Sociological Review 82(6):1188‚Äì1213.\n\nThursday - 9/18/25\nTopics:\n\nNatural Language Processing - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/23/25\nTopics:\n\nSocial Network Analysis - Lecture\n\nReadings:\n\nTabassum, Shazia, Fabiola S. Pereira, Sofia Fernandes, and Jo√£o Gama. 2018. ‚ÄúSocial Network Analysis: An Overview.‚Äù WIREs Data Mining and Knowledge Discovery 8(5).\n\nThursday - 9/25/25\nTopics:\n\nSocial Network Analysis - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 9/30/25\nTopics:\n\nAgent Based Modeling - Lecture\n\nReadings:\n\nDacrema, Eugenio, and Stefano Benati. 2020. ‚ÄúThe Mechanics of Contentious Politics: An Agent-Based Modeling Approach.‚Äù The Journal of Mathematical Sociology 44(3):163‚Äì98. doi:10.1080/0022250X.2020.1753187.\n\nThursday - 10/2/25\nTopics:\n\nAgent Based Modeling - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/7/25\nTopics:\n\nLLMs and AI - Lecture\n\nReadings:\n\nDavidson, Thomas, and Daniel Karell. 2025. ‚ÄúIntegrating Generative Artificial Intelligence into Social Science Research: Measurement, Prompting, and Simulation.‚Äù Sociological Methods & Research 54(3):775‚Äì93. doi:10.1177/00491241251339184.\n\nThursday - 10/9/25\nTopics:\n\nLLMs and AI - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/14/25\nTopics:\n\nSupervised Machine Learning - Lecture\n\nReadings:\n\n[READINGS]\n\nThursday - 10/16/25\nTopics:\n\nSupervised Machine Learning - Lab\n\nReadings:\n\n[READINGS]\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 10/21/25 [No Class - Fall Break]\nThursday - 10/23/25\nTopics:\n\nUnsupervised Machine Learning - Guest Lecture\n\nReadings:\n\n[READINGS]\n\nDue:\n\nNothing due this week.\n\n\n\n\nTuesday - 10/28/25\nTopics:\n\nUnsupervised Machine Learning - Lab\n\nReadings:\n\n[READINGS]\n\nThursday - 10/30/25\nTopics:\n\nProject Ideas Workshop\n\nReadings:\n\n[READINGS]\n\nDue:\n\nSubmit lab at the end of class on Thursday.\nProject proposals due on Canvas at 11/5/25 11:59 pm.\n\n\n\n\nTuesday - 11/4/25\nTopics:\n\nSpatial Segregation - Lecture\n\nReadings:\n\nBrazil, N. (2017). Spatial variation in the hispanic paradox: Mortality rates in new and established hispanic US destinations. Population, Space and Place, 23(1), e1968.\nCrowder, Kyle and Scott J. South. 2008.‚ÄúSpatial Dynamics of White Flight: The Effects of Local and Extralocal Racial Conditions on Neighborhood Out-Migration.‚Äù American Sociological Review 73(5):792‚Äì812.\n\nThursday - 11/6/25\nTopics:\n\nSpatial Segregation - Lab\n\nDue:\n\nSubmit lab at the end of class on Thursday.\n\n\n\n\nTuesday - 11/11/25\nTopics:\n\nProject workshop\n\nThursday - 11/13/25\nTopics:\n\nProject workshop\n\n\n\n\nTuesday - 11/18/25\nTopics:\n\nProject workshop\n\nThursday - 11/120/25\nTopics:\n\nProject workshop\n\n\n\n\nTuesday - 11/18/25\n\nPractice presentations at home\nAdditional zoom office hours for project questions\n\nThursday - 11/20/25\n\nThanksgiving\n\n\n\n\nTuesday - 11/4/25\nTopics:\n\nProject Presentations\n\nThursday - 11/6/25\nTopics:\n\nProject Presentations\nProject Presentations\n\nDue:\n\nSubmit presentation slides on Monday 12/1/25 at 5 pm.\n\n\n\n\nThursday - 12/11/25\nDue:\n\nSubmit final papers 12/11/25 at 11:59."
  },
  {
    "objectID": "schedule.html#assignment-due-dates",
    "href": "schedule.html#assignment-due-dates",
    "title": "Schedule",
    "section": "Assignment Due Dates",
    "text": "Assignment Due Dates\n\n\n\nDate\nEvent\n\n\n\n\n9/11/25 12 pm\nLab One\n\n\n9/18/25 12 pm\nLab Two\n\n\n9/25/25 12 pm\nLab Three\n\n\n10/2/25 12 pm\nLab Four\n\n\n10/9/25 12 pm\nLab Five\n\n\n10/16/25 12 pm\nLab Six\n\n\n10/30/25 12 pm\nLab Seven\n\n\n11/2/25 12 pm\nProject Proposal\n\n\n11/6/25 12 pm\nLab Eight\n\n\n12/1/25 11:59 pm\nProject Presentation Slides\n\n\n12/11/25 11:59 pm\nFinal Paper"
  }
]